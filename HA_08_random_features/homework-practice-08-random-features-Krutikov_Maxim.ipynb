{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 02.02.2024\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 19.02.2024\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 25.02.2024\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pics.shape)\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного о данных, с которыми предстоит работать:\n",
    "\n",
    "1.  x_train_pics - 3D массив изображений \n",
    "2.  x_train - развернутый в матрицу x_train_pics (каждая строка - развернутое 28x28 изображение)\n",
    "3.  y_train - массив меток классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, preprocessing, svm, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        if classifier not in ['svm', 'logreg']:\n",
    "            raise ValueError('Incorrect classifier')\n",
    "        else:\n",
    "            self.classifier = classifier\n",
    "    \n",
    "    def __PCA(self, X, train=True) -> np.ndarray:\n",
    "        if train:\n",
    "            self.pca = decomposition.PCA(n_components=self.new_dim)\n",
    "            self.pca.fit(X)            \n",
    "        X_decomposed = self.pca.transform(X)\n",
    "        return X_decomposed\n",
    "\n",
    "    def __sigma(self, X, subset_size=1000000) -> float:\n",
    "        X_dim = X.shape\n",
    "        if X_dim[0] * X_dim[1] < 2 * subset_size:\n",
    "            subset_rows = X_dim[0] // 2\n",
    "        else:\n",
    "            subset_rows = subset_size // X_dim[1]\n",
    "        \n",
    "        X_new = np.array(X)\n",
    "        np.random.shuffle(X_new)\n",
    "        eval_subset = X_new[:(2 * subset_rows)]\n",
    "        eval_subset_one = eval_subset[:subset_rows]\n",
    "        eval_subset_two = eval_subset[subset_rows:(subset_rows * 2)]\n",
    "\n",
    "        del eval_subset\n",
    "\n",
    "        substract_squared = np.power((eval_subset_one - eval_subset_two), 2)\n",
    "        for i in range(subset_rows):\n",
    "            substract_squared[i] = substract_squared[i].sum()\n",
    "        substract_squared = substract_squared[:, 0]\n",
    "        median = np.median(substract_squared)\n",
    "        # need a dot product of every row of substract_squared with I (Единичная матрица)\n",
    "        # then reshape it to a vector and find median\n",
    "        # BINGO!\n",
    "        return median\n",
    "\n",
    "    def __RFF(self, X, train=True):\n",
    "        sigma_squared = self.__sigma(X)\n",
    "        d = X.shape[1]\n",
    "        if train:\n",
    "            self.weights = np.random.normal(loc=0, scale=np.sqrt(1/sigma_squared), size=(self.n_features, d))\n",
    "            self.bias = np.random.uniform(-np.pi, np.pi, size=(self.n_features, 1))\n",
    "\n",
    "        X_RFF = np.cos( self.weights @ X.T + self.bias ).T\n",
    "        if train:\n",
    "            self.transformer = preprocessing.MinMaxScaler()\n",
    "            self.transformer.fit(X_RFF)\n",
    "        X_RFF = self.transformer.transform(X_RFF)\n",
    "        \n",
    "        # raise NotImplementedError\n",
    "        return X_RFF\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.__PCA(X)\n",
    "        else:\n",
    "            X = preprocessing.scale(X)\n",
    "        X_RFF = self.__RFF(X)\n",
    "\n",
    "        # train_set = np.concatenate((y.T, X_RFF), axis=1)\n",
    "\n",
    "        if self.classifier == 'svm':\n",
    "            self.model = svm.SVC(kernel='linear',  max_iter = 10**4)\n",
    "            # np.random.shuffle(train_set)\n",
    "            \n",
    "            self.model.fit(X_RFF, y)\n",
    "        else:\n",
    "            self.model = linear_model.LogisticRegression(max_iter = 10**3)\n",
    "            # np.random.shuffle(train_set)\n",
    "            \n",
    "            self.model.fit(X_RFF, y)\n",
    "\n",
    "        # raise NotImplementedError\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.__PCA(X, False)\n",
    "        else:\n",
    "            X = preprocessing.scale(X)\n",
    "        X_RFF = self.__RFF(X, False)\n",
    "        \n",
    "        # raise NotImplementedError\n",
    "        return self.model.predict_proba(X_RFF)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.classifier == 'svm':\n",
    "            if self.use_PCA:\n",
    "                X = self.__PCA(X, False)\n",
    "            else:\n",
    "                X = preprocessing.scale(X)\n",
    "            X_RFF = self.__RFF(X, False)\n",
    "            predictions = self.model.predict(X_RFF)\n",
    "        else:\n",
    "            probs = self.predict_proba(X)\n",
    "            predictions = np.argmax(probs, axis = 1)\n",
    "        # raise NotImplementedError\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784)\n",
      "(30000, 784)\n",
      "(30000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.5,  random_state=126)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8460666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = RFFPipeline(classifier='logreg', use_PCA=False, n_features=250)\n",
    "\n",
    "\n",
    "predictor.fit(X_train, Y_train)\n",
    "\n",
    "y_resulted = predictor.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(Y_test, y_resulted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ВАЖНЫЙ СЕБЕ УРОК__\n",
    "\n",
    "Скейлить данные для линейных моделей!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8803"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = RFFPipeline(classifier='svm')\n",
    "\n",
    "\n",
    "predictor.fit(X_train, Y_train)\n",
    "\n",
    "y_resulted = predictor.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(Y_test, y_resulted)\n",
    "# 88.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "Попробую обучить на сырых и на отскейленых данных разные модели и посмотреть на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "# sklearn kernel svm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try raw svm on scaled and unscaled\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "\n",
    "\n",
    "model_linear = svm.SVC(kernel='linear',  max_iter = 10**4)\n",
    "model_rbf = svm.SVC(kernel='rbf',  max_iter = 10**4)\n",
    "model_logreg = linear_model.LogisticRegression(max_iter = 10**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled linear SVM accuracy : 0.7414333333333334\n",
      "Unscaled rbf SVM accuracy : 0.8804333333333333\n"
     ]
    }
   ],
   "source": [
    "# fit unscaled \n",
    "\n",
    "model_linear.fit(X_train, Y_train)\n",
    "model_rbf.fit(X_train, Y_train)\n",
    "\n",
    "pred_unscaled_lin = model_linear.predict(X_test)\n",
    "pred_unscaled_rbf = model_rbf.predict(X_test)\n",
    "\n",
    "print(\"Unscaled linear SVM accuracy :\", metrics.accuracy_score(Y_test, pred_unscaled_lin))\n",
    "print(\"Unscaled rbf SVM accuracy :\", metrics.accuracy_score(Y_test, pred_unscaled_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled Logreg accuracy : 0.8281666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_logreg.fit(X_train, Y_train)\n",
    "\n",
    "pred_unscaled_logreg = model_logreg.predict(X_test)\n",
    "# pred_unscaled_logreg = np.argmax(pred_unscaled_logreg, axis = 1)\n",
    "\n",
    "print(\"Unscaled Logreg accuracy :\", metrics.accuracy_score(Y_test, pred_unscaled_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit scaled\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_linear\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, Y_train)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel_rbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model_logreg\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, Y_train)\n\u001b[0;32m      7\u001b[0m pred_scaled_lin \u001b[38;5;241m=\u001b[39m model_linear\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32mc:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\Max\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit scaled\n",
    "\n",
    "model_linear.fit(X_train_scaled, Y_train)\n",
    "model_rbf.fit(X_train_scaled, Y_train)\n",
    "model_logreg.fit(X_train_scaled, Y_train)\n",
    "\n",
    "pred_scaled_lin = model_linear.predict(X_test_scaled)\n",
    "pred_scaled_rbf = model_rbf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Scaled linear SVM accuracy :\", metrics.accuracy_score(Y_test, pred_scaled_lin))\n",
    "print(\"Scaled rbf SVM accuracy :\", metrics.accuracy_score(Y_test, pred_scaled_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Logreg accuracy : 0.8313666666666667\n"
     ]
    }
   ],
   "source": [
    "pred_scaled_logreg = model_logreg.predict(X_test_scaled)\n",
    "print(\"Scaled Logreg accuracy :\", metrics.accuracy_score(Y_test, pred_scaled_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вылезли некоторые ошибки, потому что я не проверяю код перед запуском ахаха))\n",
    "\n",
    "Но рассмотрим то, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linreg_PCA = RFFPipeline(n_features=1000, classifier='logreg')\n",
    "model_svm_PCA = RFFPipeline(n_features=1000, classifier='svm')\n",
    "\n",
    "model_linreg = RFFPipeline(n_features=1000, classifier='logreg', use_PCA=False)\n",
    "model_svm = RFFPipeline(n_features=1000, classifier='svm', use_PCA=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFFPipeline(classifier=&#x27;svm&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFFPipeline</label><div class=\"sk-toggleable__content\"><pre>RFFPipeline(classifier=&#x27;svm&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFFPipeline(classifier='svm')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linreg_PCA.fit(X_train, Y_train)\n",
    "model_svm_PCA.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFFPipeline(classifier=&#x27;svm&#x27;, use_PCA=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFFPipeline</label><div class=\"sk-toggleable__content\"><pre>RFFPipeline(classifier=&#x27;svm&#x27;, use_PCA=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFFPipeline(classifier='svm', use_PCA=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_linreg.fit(X_train, Y_train)\n",
    "model_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_linreg_PCA = model_linreg_PCA.predict(X_test)\n",
    "predict_svm_PCA = model_svm_PCA.predict(X_test)\n",
    "\n",
    "predict_linreg = model_linreg.predict(X_test)\n",
    "predict_svm = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF SVM accuracy with PCA : 0.8804333333333333\n",
      "RFF Logreg accuracy with PCA : 0.8802666666666666\n",
      "RFF SVM accuracy without PCA : 0.8650333333333333\n",
      "RFF Logreg accuracy without PCA : 0.8667333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"RFF SVM accuracy with PCA :\", metrics.accuracy_score(Y_test, predict_svm_PCA))\n",
    "print(\"RFF Logreg accuracy with PCA :\", metrics.accuracy_score(Y_test, predict_linreg_PCA))\n",
    "print(\"RFF SVM accuracy without PCA :\", metrics.accuracy_score(Y_test, predict_svm))\n",
    "print(\"RFF Logreg accuracy without PCA :\", metrics.accuracy_score(Y_test, predict_linreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__UNSCALED RAW__\n",
    "\n",
    "Unscaled linear SVM accuracy : 0.7414333333333334\n",
    "\n",
    "Unscaled rbf SVM accuracy : 0.8804333333333333\n",
    "\n",
    "Unscaled Logreg accuracy : 0.8293666666666667\n",
    "\n",
    "__SCALED RAW__\n",
    "\n",
    "Scaled linear SVM accuracy : 0.7573666666666666\n",
    "\n",
    "Scaled rbf SVM accuracy : 0.8815\n",
    "\n",
    "Scaled Logreg accuracy : 0.8313666666666667\n",
    "\n",
    "__NEW FEATURES PCA (n_features = 250, new_dim = 50)__\n",
    "\n",
    "RFF SVM accuracy with PCA : 0.8673\n",
    "\n",
    "RFF Logreg accuracy with PCA : 0.8635333333333334\n",
    "\n",
    "__NEW FEATURES NO PCA (n_features = 250)__\n",
    "\n",
    "RFF SVM accuracy without PCA : 0.8473666666666667\n",
    "\n",
    "RFF Logreg accuracy without PCA : 0.8429666666666666\n",
    "\n",
    "__NEW FEATURES PCA (n_features = 1000, new_dim = 50)__\n",
    "\n",
    "RFF SVM accuracy with PCA : 0.8804333333333333\n",
    "\n",
    "RFF Logreg accuracy with PCA : 0.8802666666666666\n",
    "\n",
    "__NEW FEATURES NO PCA (n_features = 1000)__\n",
    "\n",
    "RFF SVM accuracy without PCA : 0.8650333333333333\n",
    "\n",
    "RFF Logreg accuracy without PCA : 0.8667333333333334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы? \n",
    "\n",
    "RFF + SVM очень похож по точности на RBF (radial basis function) SVM, что в целом и логично. Мы хорошо аппроксимируем ядро. По времени вроде все плюс минус одинаково. \n",
    "Забавно, что RFF + SVM дает такой же скор, как и unscaled RBF SVM, а наивысший скор у scaled RBF SVM\n",
    "\n",
    "Чистый (линейный) SVM и со скейлингом и без него работает очень плохо в сравнении с другими методами. Сложно построить разделяющую гиперплоскость для таких данных. \n",
    "\n",
    "Сразу можно увидеть, что PCA позволяет немного, но улучшить модель, добившись лишних сотых. \n",
    "На удивление логрег с RFF работает столь же точно, как и SVM + RFF, без RFF разница сильно заметна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время для CatBoost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as ctb\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=70)\n",
    "\n",
    "pca.fit(X_train) \n",
    "X_train_PCA = pca.transform(X_train)\n",
    "\n",
    "pca.fit(X_test) \n",
    "X_test_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.2840427\ttotal: 93ms\tremaining: 23.2s\n",
      "249:\tlearn: 0.8212714\ttotal: 24.1s\tremaining: 0us\n",
      "0:\tlearn: 2.2816037\ttotal: 98.3ms\tremaining: 24.5s\n",
      "249:\tlearn: 0.8357887\ttotal: 23.6s\tremaining: 0us\n",
      "0:\tlearn: 2.2783356\ttotal: 93.2ms\tremaining: 23.2s\n",
      "249:\tlearn: 0.8458624\ttotal: 25.9s\tremaining: 0us\n",
      "0:\tlearn: 2.2812901\ttotal: 93.3ms\tremaining: 23.2s\n",
      "249:\tlearn: 0.8272565\ttotal: 23.4s\tremaining: 0us\n",
      "0:\tlearn: 2.2785091\ttotal: 88.7ms\tremaining: 22.1s\n",
      "249:\tlearn: 0.8328208\ttotal: 23.4s\tremaining: 0us\n",
      "0:\tlearn: 2.2114291\ttotal: 91.3ms\tremaining: 22.7s\n",
      "249:\tlearn: 0.3360161\ttotal: 23.1s\tremaining: 0us\n",
      "0:\tlearn: 2.1994584\ttotal: 86.5ms\tremaining: 21.5s\n",
      "249:\tlearn: 0.3346184\ttotal: 23.4s\tremaining: 0us\n",
      "0:\tlearn: 2.1834413\ttotal: 89.1ms\tremaining: 22.2s\n",
      "249:\tlearn: 0.3419344\ttotal: 23.3s\tremaining: 0us\n",
      "0:\tlearn: 2.1978514\ttotal: 89.6ms\tremaining: 22.3s\n",
      "249:\tlearn: 0.3314665\ttotal: 23.4s\tremaining: 0us\n",
      "0:\tlearn: 2.1840822\ttotal: 91.9ms\tremaining: 22.9s\n",
      "249:\tlearn: 0.3228771\ttotal: 23.2s\tremaining: 0us\n",
      "0:\tlearn: 2.1245569\ttotal: 98.7ms\tremaining: 24.6s\n",
      "249:\tlearn: 0.1966106\ttotal: 23.2s\tremaining: 0us\n",
      "0:\tlearn: 2.1012006\ttotal: 88.2ms\tremaining: 21.9s\n",
      "249:\tlearn: 0.1982328\ttotal: 23.4s\tremaining: 0us\n",
      "0:\tlearn: 2.0701397\ttotal: 89.8ms\tremaining: 22.4s\n",
      "249:\tlearn: 0.2008655\ttotal: 23.1s\tremaining: 0us\n",
      "0:\tlearn: 2.0978534\ttotal: 90.9ms\tremaining: 22.6s\n",
      "249:\tlearn: 0.1947913\ttotal: 23.5s\tremaining: 0us\n",
      "0:\tlearn: 2.0708162\ttotal: 98.5ms\tremaining: 24.5s\n",
      "249:\tlearn: 0.1860367\ttotal: 26.2s\tremaining: 0us\n",
      "0:\tlearn: 2.2840427\ttotal: 122ms\tremaining: 1m\n",
      "499:\tlearn: 0.5875434\ttotal: 49.6s\tremaining: 0us\n",
      "0:\tlearn: 2.2816037\ttotal: 93ms\tremaining: 46.4s\n",
      "499:\tlearn: 0.5970993\ttotal: 49.2s\tremaining: 0us\n",
      "0:\tlearn: 2.2783356\ttotal: 95ms\tremaining: 47.4s\n",
      "499:\tlearn: 0.6045757\ttotal: 49.4s\tremaining: 0us\n",
      "0:\tlearn: 2.2812901\ttotal: 92.3ms\tremaining: 46.1s\n",
      "499:\tlearn: 0.5851923\ttotal: 49.5s\tremaining: 0us\n",
      "0:\tlearn: 2.2785091\ttotal: 102ms\tremaining: 50.7s\n",
      "499:\tlearn: 0.5900161\ttotal: 49.3s\tremaining: 0us\n",
      "0:\tlearn: 2.2114291\ttotal: 97.2ms\tremaining: 48.5s\n",
      "499:\tlearn: 0.1953802\ttotal: 48.8s\tremaining: 0us\n",
      "0:\tlearn: 2.1994584\ttotal: 94.7ms\tremaining: 47.3s\n",
      "499:\tlearn: 0.1998729\ttotal: 49.6s\tremaining: 0us\n",
      "0:\tlearn: 2.1834413\ttotal: 89.9ms\tremaining: 44.9s\n",
      "499:\tlearn: 0.2007462\ttotal: 49s\tremaining: 0us\n",
      "0:\tlearn: 2.1978514\ttotal: 90.3ms\tremaining: 45.1s\n",
      "499:\tlearn: 0.1916080\ttotal: 49.3s\tremaining: 0us\n",
      "0:\tlearn: 2.1840822\ttotal: 96.8ms\tremaining: 48.3s\n",
      "499:\tlearn: 0.1868246\ttotal: 49.2s\tremaining: 0us\n",
      "0:\tlearn: 2.1245569\ttotal: 89.9ms\tremaining: 44.8s\n",
      "499:\tlearn: 0.0908490\ttotal: 48.2s\tremaining: 0us\n",
      "0:\tlearn: 2.1012006\ttotal: 107ms\tremaining: 53.5s\n",
      "499:\tlearn: 0.0932089\ttotal: 48.4s\tremaining: 0us\n",
      "0:\tlearn: 2.0701397\ttotal: 93.2ms\tremaining: 46.5s\n",
      "499:\tlearn: 0.0931709\ttotal: 47.9s\tremaining: 0us\n",
      "0:\tlearn: 2.0978534\ttotal: 103ms\tremaining: 51.3s\n",
      "499:\tlearn: 0.0904840\ttotal: 47.9s\tremaining: 0us\n",
      "0:\tlearn: 2.0708162\ttotal: 95.3ms\tremaining: 47.5s\n",
      "499:\tlearn: 0.0878216\ttotal: 48.7s\tremaining: 0us\n",
      "0:\tlearn: 2.2840427\ttotal: 98.1ms\tremaining: 1m 38s\n",
      "999:\tlearn: 0.3838877\ttotal: 1m 37s\tremaining: 0us\n",
      "0:\tlearn: 2.2816037\ttotal: 102ms\tremaining: 1m 41s\n",
      "999:\tlearn: 0.3903868\ttotal: 1m 38s\tremaining: 0us\n",
      "0:\tlearn: 2.2783356\ttotal: 93.3ms\tremaining: 1m 33s\n",
      "999:\tlearn: 0.3977635\ttotal: 1m 38s\tremaining: 0us\n",
      "0:\tlearn: 2.2812901\ttotal: 98.3ms\tremaining: 1m 38s\n",
      "999:\tlearn: 0.3814190\ttotal: 1m 37s\tremaining: 0us\n",
      "0:\tlearn: 2.2785091\ttotal: 102ms\tremaining: 1m 42s\n",
      "999:\tlearn: 0.3820201\ttotal: 1m 39s\tremaining: 0us\n",
      "0:\tlearn: 2.2114291\ttotal: 92.5ms\tremaining: 1m 32s\n",
      "999:\tlearn: 0.0913365\ttotal: 1m 36s\tremaining: 0us\n",
      "0:\tlearn: 2.1994584\ttotal: 99.5ms\tremaining: 1m 39s\n",
      "999:\tlearn: 0.0928776\ttotal: 1m 36s\tremaining: 0us\n",
      "0:\tlearn: 2.1834413\ttotal: 91.9ms\tremaining: 1m 31s\n",
      "999:\tlearn: 0.0929958\ttotal: 1m 35s\tremaining: 0us\n",
      "0:\tlearn: 2.1978514\ttotal: 96.7ms\tremaining: 1m 36s\n",
      "999:\tlearn: 0.0907551\ttotal: 1m 35s\tremaining: 0us\n",
      "0:\tlearn: 2.1840822\ttotal: 93.1ms\tremaining: 1m 32s\n",
      "999:\tlearn: 0.0867723\ttotal: 1m 40s\tremaining: 0us\n",
      "0:\tlearn: 2.1245569\ttotal: 101ms\tremaining: 1m 40s\n",
      "999:\tlearn: 0.0334044\ttotal: 1m 45s\tremaining: 0us\n",
      "0:\tlearn: 2.1012006\ttotal: 96.6ms\tremaining: 1m 36s\n",
      "999:\tlearn: 0.0342154\ttotal: 1m 42s\tremaining: 0us\n",
      "0:\tlearn: 2.0701397\ttotal: 136ms\tremaining: 2m 16s\n",
      "999:\tlearn: 0.0344470\ttotal: 1m 40s\tremaining: 0us\n",
      "0:\tlearn: 2.0978534\ttotal: 93ms\tremaining: 1m 32s\n",
      "999:\tlearn: 0.0328312\ttotal: 1m 42s\tremaining: 0us\n",
      "0:\tlearn: 2.0708162\ttotal: 110ms\tremaining: 1m 50s\n",
      "999:\tlearn: 0.0311565\ttotal: 1m 43s\tremaining: 0us\n",
      "0:\tlearn: 2.0593055\ttotal: 101ms\tremaining: 1m 40s\n",
      "999:\tlearn: 0.0364839\ttotal: 1m 49s\tremaining: 0us\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m clf \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39mGridSearchCV(model, param_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train_PCA[:\u001b[38;5;241m3000\u001b[39m], Y_train[:\u001b[38;5;241m3000\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params'"
     ]
    }
   ],
   "source": [
    "model = ctb.CatBoostClassifier(verbose=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'iterations' : [250, 500, 1000],\n",
    "    'learning_rate' : [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "clf = sklearn.model_selection.GridSearchCV(model, param_grid, scoring='accuracy')\n",
    "clf.fit(X_train_PCA[:3000], Y_train[:3000])\n",
    "\n",
    "clf.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1000, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9643246\ttotal: 188ms\tremaining: 3m 7s\n",
      "700:\tlearn: 0.1771013\ttotal: 2m 24s\tremaining: 1m 1s\n",
      "999:\tlearn: 0.1342620\ttotal: 3m 21s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x13eef25eed0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ctb.CatBoostClassifier(iterations=1000, learning_rate=0.1, verbose=700)\n",
    "model.fit(X_train_PCA, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB accuracy with PCA (new_dim = 70): 0.3584333333333333\n"
     ]
    }
   ],
   "source": [
    "catboost_prediction = model.predict(X_test_PCA)\n",
    "\n",
    "print(\"GB accuracy with PCA (new_dim = 70):\", metrics.accuracy_score(Y_test, catboost_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг дал слишком низкий скор, это может быть связано с маленьким количеством фич после PCA, или с чем либо другим, времени проверить досконально не остается:("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим сразу несколько моделей и протестируем их accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = 100  0.8548333333333333\n",
      "n_features = 500  0.8782916666666667\n"
     ]
    }
   ],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "# Протестируем влияние разного количеств фич на SVM \n",
    "model_svm_100 = RFFPipeline(classifier='svm', n_features=100)\n",
    "model_svm_500 = RFFPipeline(classifier='svm', n_features=500)\n",
    "\n",
    "model_svm_100.fit(X_train, Y_train)\n",
    "model_svm_500.fit(X_train, Y_train)\n",
    "\n",
    "y_100 = model_svm_100.predict(X_test)\n",
    "y_500 = model_svm_500.predict(X_test)\n",
    "\n",
    "print(\"n_features = 100 \",metrics.accuracy_score(Y_test, y_100))\n",
    "print(\"n_features = 500 \",metrics.accuracy_score(Y_test, y_500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = 2000  0.88\n"
     ]
    }
   ],
   "source": [
    "model_svm_2000 = RFFPipeline(classifier='svm', n_features=2000)\n",
    "model_svm_2000.fit(X_train, Y_train)\n",
    "\n",
    "y_2000 = model_svm_2000.predict(X_test)\n",
    "\n",
    "print(\"n_features = 2000 \",metrics.accuracy_score(Y_test, y_2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " n_features:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " n_features:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8543333333333333, 0.873375, 0.8784583333333333, 0.8829166666666667, 0.883875, 0.8776666666666667, 0.8814583333333333]\n",
      "[0.8435833333333334, 0.8669583333333334, 0.8745416666666667, 0.8797916666666666, 0.8830833333333333, 0.887375, 0.8883333333333333]\n"
     ]
    }
   ],
   "source": [
    "n_features_array = [100, 250, 500, 1000, 1250, 1700, 2000]\n",
    "classifier_array = ['svm', 'logreg']\n",
    "\n",
    "svm_accuracy = []\n",
    "logreg_accuracy = []\n",
    "\n",
    "for element_1 in n_features_array:\n",
    "    for element_2 in classifier_array:\n",
    "        print(\"classifier: \", element_2, '\\n', 'n_features: ', element_1)\n",
    "        model = RFFPipeline(classifier=element_2, n_features=element_1)\n",
    "        model.fit(X_train, Y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(Y_test, prediction)\n",
    "        if element_2 == 'svm':\n",
    "            svm_accuracy.append(accuracy)\n",
    "        else:\n",
    "            logreg_accuracy.append(accuracy)\n",
    "\n",
    "print(svm_accuracy)\n",
    "print(logreg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_array = [100, 250, 500, 1000, 1250, 1700, 2000]\n",
    "svm_accuracy = [0.8543333333333333, 0.873375, 0.8784583333333333, 0.8829166666666667, 0.883875, 0.8776666666666667, 0.8814583333333333]\n",
    "logreg_accuracy = [0.8435833333333334, 0.8669583333333334, 0.8745416666666667, 0.8797916666666666, 0.8830833333333333, 0.887375, 0.8883333333333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = np.array([n_features_array, svm_accuracy, logreg_accuracy]).T\n",
    "\n",
    "accuracy_data = pd.DataFrame(accuracy_data, columns=['n_features', 'svm', 'logreg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>svm</th>\n",
       "      <th>logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>0.843583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.873375</td>\n",
       "      <td>0.866958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>0.878458</td>\n",
       "      <td>0.874542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.882917</td>\n",
       "      <td>0.879792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.883083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1700.0</td>\n",
       "      <td>0.877667</td>\n",
       "      <td>0.887375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.881458</td>\n",
       "      <td>0.888333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features       svm    logreg\n",
       "0       100.0  0.854333  0.843583\n",
       "1       250.0  0.873375  0.866958\n",
       "2       500.0  0.878458  0.874542\n",
       "3      1000.0  0.882917  0.879792\n",
       "4      1250.0  0.883875  0.883083\n",
       "5      1700.0  0.877667  0.887375\n",
       "6      2000.0  0.881458  0.888333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23b208e18d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x='n_features',\n",
    "            y='svm',\n",
    "            data=accuracy_data,\n",
    "            #label='svm',\n",
    "            lw=3)\n",
    "sns.lineplot(x='n_features',\n",
    "            y='logreg',\n",
    "            data=accuracy_data,\n",
    "            color='r',\n",
    "            #label='logreg',\n",
    "            lw=3)\n",
    "\n",
    "plt.xlabel('n_features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(labels=['svm', 'logreg'] ,title='Model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ремарка__\n",
    "\n",
    "Я не рискнул тестировать на n_features более 2000, так как время выполнения уже на 2000 тысячах превышает 20 минут. \n",
    "\n",
    "Однако, на данной выборке параметров n_features видно резкий подъем где-то до 1250 фич, а дальше плюс минус стабильно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробую поменять значения PCA разложения с константным количеством n_features (250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " new_dim:  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " new_dim:  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " new_dim:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " new_dim:  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " new_dim:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " new_dim:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " new_dim:  250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " new_dim:  250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  svm \n",
      " new_dim:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier:  logreg \n",
      " new_dim:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8690416666666667, 0.872125, 0.870625, 0.863375, 0.8605]\n",
      "[0.865, 0.8654583333333333, 0.8643333333333333, 0.8572916666666667, 0.8507916666666666]\n"
     ]
    }
   ],
   "source": [
    "pca_array = [50, 75, 100, 250, 400]\n",
    "classifier_array = ['svm', 'logreg']\n",
    "\n",
    "svm_PCA_accuracy = []\n",
    "logreg_PCA_accuracy = []\n",
    "\n",
    "for element_1 in pca_array:\n",
    "    for element_2 in classifier_array:\n",
    "        print(\"classifier: \", element_2, '\\n', 'new_dim: ', element_1)\n",
    "        model = RFFPipeline(classifier=element_2, n_features=250, new_dim=element_1)\n",
    "        model.fit(X_train, Y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(Y_test, prediction)\n",
    "        if element_2 == 'svm':\n",
    "            svm_PCA_accuracy.append(accuracy)\n",
    "        else:\n",
    "            logreg_PCA_accuracy.append(accuracy)\n",
    "\n",
    "print(svm_PCA_accuracy)\n",
    "print(logreg_PCA_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_array = [50, 75, 100, 250, 400]\n",
    "\n",
    "svm_PCA_accuracy = [0.8690416666666667, 0.872125, 0.870625, 0.863375, 0.8605]\n",
    "logreg_PCA_accuracy = [0.865, 0.8654583333333333, 0.8643333333333333, 0.8572916666666667, 0.8507916666666666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca</th>\n",
       "      <th>svm</th>\n",
       "      <th>logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.869042</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.872125</td>\n",
       "      <td>0.865458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.870625</td>\n",
       "      <td>0.864333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.857292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400.0</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.850792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pca       svm    logreg\n",
       "0   50.0  0.869042  0.865000\n",
       "1   75.0  0.872125  0.865458\n",
       "2  100.0  0.870625  0.864333\n",
       "3  250.0  0.863375  0.857292\n",
       "4  400.0  0.860500  0.850792"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_data_pca = np.array([pca_array, svm_PCA_accuracy, logreg_PCA_accuracy]).T\n",
    "\n",
    "accuracy_data_pca = pd.DataFrame(accuracy_data_pca, columns=['pca', 'svm', 'logreg'])\n",
    "accuracy_data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23b20ac7f10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x='pca',\n",
    "            y='svm',\n",
    "            data=accuracy_data_pca,\n",
    "            #label='svm',\n",
    "            lw=3)\n",
    "sns.lineplot(x='pca',\n",
    "            y='logreg',\n",
    "            data=accuracy_data_pca,\n",
    "            color='r',\n",
    "            #label='logreg',\n",
    "            lw=3)\n",
    "\n",
    "plt.xlabel('pca New Dim')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(labels=['svm', 'logreg'] ,title='Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что у обоих моделей максимальная точность получается на разложении в примерно 70, далее точность падает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 1 балл)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline_var_funcs(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, func='cos', classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        func, string: 'cos', 'sin', 'exp', 'tanh', 'sigmoid', 'sign', 'None'\n",
    "\n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        if func not in ['cos', 'sin', 'exp', 'tanh', 'sigmoid', 'sign', 'None']:\n",
    "            raise ValueError('Incorrect function')\n",
    "        else:\n",
    "            self.func = func\n",
    "\n",
    "        if classifier not in ['svm', 'logreg']:\n",
    "            raise ValueError('Incorrect classifier')\n",
    "        else:\n",
    "            self.classifier = classifier\n",
    "    \n",
    "    def __PCA(self, X, train=True) -> np.ndarray:\n",
    "        if train:\n",
    "            self.pca = decomposition.PCA(n_components=self.new_dim)\n",
    "            self.pca.fit(X)            \n",
    "        X_decomposed = self.pca.transform(X)\n",
    "        return X_decomposed\n",
    "\n",
    "    def __sigma(self, X, subset_size=1000000) -> float:\n",
    "        X_dim = X.shape\n",
    "        if X_dim[0] * X_dim[1] < 2 * subset_size:\n",
    "            subset_rows = X_dim[0] // 2\n",
    "        else:\n",
    "            subset_rows = subset_size // X_dim[1]\n",
    "        \n",
    "        X_new = np.array(X)\n",
    "        np.random.shuffle(X_new)\n",
    "        eval_subset = X_new[:(2 * subset_rows)]\n",
    "        eval_subset_one = eval_subset[:subset_rows]\n",
    "        eval_subset_two = eval_subset[subset_rows:(subset_rows * 2)]\n",
    "        del eval_subset\n",
    "\n",
    "        substract_squared = np.power((eval_subset_one - eval_subset_two), 2)\n",
    "        for i in range(subset_rows):\n",
    "            substract_squared[i] = substract_squared[i].sum()\n",
    "        median = np.median(substract_squared)\n",
    "\n",
    "        return median\n",
    "\n",
    "    def __RFF(self, X, train=True): \n",
    "        def sigmoid(x) -> np.float32:\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        sigma_squared = self.__sigma(X)\n",
    "        d = X.shape[1]\n",
    "        if train:\n",
    "            self.weights = np.random.normal(loc=0, scale=np.sqrt(1/sigma_squared), size=(self.n_features, d))\n",
    "            self.bias = np.random.uniform(-np.pi, np.pi, size=(self.n_features, 1))\n",
    "\n",
    "        match self.func:\n",
    "            case 'cos':\n",
    "                X_RFF = np.cos( self.weights @ X.T + self.bias ).T\n",
    "            case 'sin':\n",
    "                X_RFF = np.sin( self.weights @ X.T + self.bias ).T\n",
    "            case 'exp':\n",
    "                X_RFF = np.exp( self.weights @ X.T + self.bias ).T\n",
    "            case 'tanh':\n",
    "                X_RFF = np.tanh( self.weights @ X.T + self.bias ).T\n",
    "            case 'sigmoid':\n",
    "                X_RFF = sigmoid( self.weights @ X.T + self.bias ).T\n",
    "            case 'sign':\n",
    "                X_RFF = np.sign( self.weights @ X.T + self.bias ).T\n",
    "            case 'None':\n",
    "                X_RFF = ( self.weights @ X.T + self.bias ).T\n",
    "        \n",
    "        # print(X_RFF)\n",
    "        if train:\n",
    "            self.transformer = preprocessing.MinMaxScaler()\n",
    "            self.transformer.fit(X_RFF)\n",
    "        X_RFF = self.transformer.transform(X_RFF)\n",
    "        \n",
    "        return X_RFF\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.__PCA(X)\n",
    "        X_RFF = self.__RFF(X)\n",
    "        if self.classifier == 'svm':\n",
    "            self.model = svm.SVC(kernel='linear',  max_iter = 10**4)\n",
    "            self.model.fit(X_RFF, y)\n",
    "        else:\n",
    "            self.model = linear_model.LogisticRegression(max_iter = 10**3)\n",
    "            self.model.fit(X_RFF, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.__PCA(X, False)\n",
    "        X_RFF = self.__RFF(X, False)\n",
    "        \n",
    "        return self.model.predict_proba(X_RFF)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.classifier == 'svm':\n",
    "            if self.use_PCA:\n",
    "                X = self.__PCA(X, False)\n",
    "            X_RFF = self.__RFF(X, False)\n",
    "            predictions = self.model.predict(X_RFF)\n",
    "        else:\n",
    "            probs = self.predict_proba(X)\n",
    "            predictions = np.argmax(probs, axis = 1)\n",
    "\n",
    "        return predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\maxxi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8702083333333334, 0.8704583333333333, 0.858625, 0.8649166666666667, 0.863125, 0.7840833333333334, 0.8479166666666667]\n",
      "[0.8647083333333333, 0.8627083333333333, 0.8505416666666666, 0.8579583333333334, 0.8539166666666667, 0.7932083333333333, 0.8355]\n"
     ]
    }
   ],
   "source": [
    "func_array = ['cos', 'sin', 'exp', 'tanh', 'sigmoid', 'sign', 'None']\n",
    "classifier_array = ['svm', 'logreg']\n",
    "\n",
    "svm_func_accuracy = []\n",
    "logreg_func_accuracy = []\n",
    "\n",
    "for element_1 in classifier_array:\n",
    "    for element_2 in func_array:\n",
    "        model = RFFPipeline_var_funcs(n_features=250, func=element_2, classifier=element_1)\n",
    "        model.fit(X_train, Y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(Y_test, prediction)\n",
    "        if element_1 == 'svm':\n",
    "            svm_func_accuracy.append(accuracy)\n",
    "        else:\n",
    "            logreg_func_accuracy.append(accuracy)\n",
    "\n",
    "print(svm_func_accuracy)\n",
    "print(logreg_func_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>svm</th>\n",
       "      <th>logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cos</td>\n",
       "      <td>0.8702083333333334</td>\n",
       "      <td>0.8647083333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sin</td>\n",
       "      <td>0.8704583333333333</td>\n",
       "      <td>0.8627083333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp</td>\n",
       "      <td>0.858625</td>\n",
       "      <td>0.8505416666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.8649166666666667</td>\n",
       "      <td>0.8579583333333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.863125</td>\n",
       "      <td>0.8539166666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sign</td>\n",
       "      <td>0.7840833333333334</td>\n",
       "      <td>0.7932083333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>0.8479166666666667</td>\n",
       "      <td>0.8355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  function                 svm              logreg\n",
       "0      cos  0.8702083333333334  0.8647083333333333\n",
       "1      sin  0.8704583333333333  0.8627083333333333\n",
       "2      exp            0.858625  0.8505416666666666\n",
       "3     tanh  0.8649166666666667  0.8579583333333334\n",
       "4  sigmoid            0.863125  0.8539166666666667\n",
       "5     sign  0.7840833333333334  0.7932083333333333\n",
       "6     None  0.8479166666666667              0.8355"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_func_accuracy = [0.8702083333333334, 0.8704583333333333, 0.858625, 0.8649166666666667, 0.863125, 0.7840833333333334, 0.8479166666666667]\n",
    "logreg_func_accuracy = [0.8647083333333333, 0.8627083333333333, 0.8505416666666666, 0.8579583333333334, 0.8539166666666667, 0.7932083333333333, 0.8355]\n",
    "\n",
    "accuracy_data_func = np.array([func_array, svm_func_accuracy, logreg_func_accuracy]).T\n",
    "\n",
    "accuracy_data_func = pd.DataFrame(accuracy_data_pca, columns=['function', 'svm', 'logreg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>score</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cos</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sin</td>\n",
       "      <td>0.870458</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp</td>\n",
       "      <td>0.858625</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.864917</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.863125</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sign</td>\n",
       "      <td>0.784083</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>0.847917</td>\n",
       "      <td>svm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cos</td>\n",
       "      <td>0.864708</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sin</td>\n",
       "      <td>0.862708</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>exp</td>\n",
       "      <td>0.850542</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.857958</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.853917</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sign</td>\n",
       "      <td>0.793208</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>0.835500</td>\n",
       "      <td>logreg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   function     score  solver\n",
       "0       cos  0.870208     svm\n",
       "1       sin  0.870458     svm\n",
       "2       exp  0.858625     svm\n",
       "3      tanh  0.864917     svm\n",
       "4   sigmoid  0.863125     svm\n",
       "5      sign  0.784083     svm\n",
       "6      None  0.847917     svm\n",
       "7       cos  0.864708  logreg\n",
       "8       sin  0.862708  logreg\n",
       "9       exp  0.850542  logreg\n",
       "10     tanh  0.857958  logreg\n",
       "11  sigmoid  0.853917  logreg\n",
       "12     sign  0.793208  logreg\n",
       "13     None  0.835500  logreg"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_double = func_array * 2\n",
    "ans_array = svm_func_accuracy + logreg_func_accuracy\n",
    "solv_array = ['svm'] * 7 + ['logreg'] * 7\n",
    "\n",
    "accuracy_data_func_new = np.array([func_double, ans_array, solv_array]).T\n",
    "accuracy_data_func_new = pd.DataFrame(accuracy_data_func_new, columns=['function', 'score', 'solver'])\n",
    "\n",
    "accuracy_data_func_new['score'] = pd.to_numeric(accuracy_data_func_new['score'])\n",
    "accuracy_data_func_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(\n",
    "    data=accuracy_data_func_new,\n",
    "    x='function',\n",
    "    y='score',\n",
    "    hue='solver'\n",
    ")\n",
    "plt.ylim(0.75, 1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно видеть, нет большой разницы в том, какую функцию использовать (только на sign имеется некоторая просадка). Это можно связать с тем, что PCA очень хорошо преобразует фичи, понижая в некоторой степени разряженные данные картинок в плотный вектор размера new_Dim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6. (Максимум 1 балл)__\n",
    "\n",
    "Реализуйте класс ядровой Ridge регрессии (Лекция 13, $\\S 1.2$), для оптимизации используте градиентный спуск, а не аналитическую формулу. Также подумайте о том, как в формулах правильно учесть свободный коэффициент. Затем адаптируйте вашу реализацию RFF под задачу регрессии. Сравните вашу ядровую регрессию и RFF на синтетических данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потерь: \n",
    "$$\n",
    "Q(w) = \\frac{1}{2} ||\\Phi \\Phi^T w - y||^2 + \\frac{\\lambda}{2} w^T \\Phi \\Phi^T w \\rightarrow \\min_w,\n",
    "$$\n",
    "где $\\Phi \\Phi^T = K$, $K = (k(x_i, x_j))_{i, j = 1}^{\\ell}$.\n",
    "\n",
    "Предсказание: \n",
    "$\n",
    "y(x) = k(x)^T w,\n",
    "$\n",
    "где $k(x)$ — вектор функций ядра от пар объектов $(x, x_i)_{i=1}^{\\ell}$.\n",
    "\n",
    "Вы можете изменять представленный ниже шаблон по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "class KernelRidgeRegression(RegressorMixin):\n",
    "    \"\"\"\n",
    "    Kernel Ridge regression class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,         \n",
    "        lr=0.01,\n",
    "        regularization=1.,\n",
    "        tolerance=1e-2,\n",
    "        max_iter=1000,\n",
    "        batch_size=64,\n",
    "        kernel_scale=1.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param lr: learning rate\n",
    "        :param regularization: regularization coefficient\n",
    "        :param tolerance: stopping criterion for square of euclidean norm of weight difference\n",
    "        :param max_iter: stopping criterion for iterations\n",
    "        :param batch_size: size of the batches used in gradient descent steps\n",
    "        :parame kernel_scale: length scale in RBF kernel formula\n",
    "        \"\"\"\n",
    "\n",
    "        self.lr: float = lr\n",
    "        self.regularization: float = regularization\n",
    "        self.w: np.ndarray | None = None\n",
    "\n",
    "        self.tolerance: float = tolerance\n",
    "        self.max_iter: int = max_iter\n",
    "        self.batch_size: int = batch_size\n",
    "        self.loss_history: list[float] = []\n",
    "        self.kernel = RBF(kernel_scale)\n",
    "\n",
    "    def calc_loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculating loss for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def calc_grad(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculating gradient for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> \"KernelRidgeRegression\":\n",
    "        \"\"\"\n",
    "        Fitting weights for x and y dataset\n",
    "        :param x: features array\n",
    "        :param y: targets array\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicting targets for x dataset\n",
    "        :param x: features array\n",
    "        :return: prediction: np.ndarray\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(array, need, count):\n",
    "    counter = 0\n",
    "    final_array = [need]\n",
    "    while (need in array) and (counter != count):\n",
    "        final_array.append(need)\n",
    "        array.pop(array.index(need))\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= count:\n",
    "        return 0\n",
    "\n",
    "    while counter < count:\n",
    "        step_min = min(final_array)\n",
    "        step_max = max(final_array)\n",
    "        potential_min = min(array, key=lambda x: abs(x - step_min))\n",
    "        potential_max = min(array, key=lambda x: abs(x - step_max))\n",
    "        print(step_min, step_max)\n",
    "        print(potential_min, potential_max)\n",
    "        print('\\n')\n",
    "        if potential_max - step_min < step_max - potential_min:\n",
    "            array.pop(array.index(potential_max))\n",
    "            final_array.append(potential_max)\n",
    "        else:\n",
    "            array.pop(array.index(potential_min))\n",
    "            final_array.append(potential_min)\n",
    "        counter += 1\n",
    "    return max(final_array) - min(final_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "3 3\n",
      "\n",
      "\n",
      "3 5\n",
      "7 7\n",
      "\n",
      "\n",
      "3 7\n",
      "9 9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference([3, 7, 9, 10], 5, 3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
