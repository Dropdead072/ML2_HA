{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 9. EM-алгоритм\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 28.02.2024\n",
    "\n",
    "Мягкий дедлайн: 19.03.2024 23:59 MSK\n",
    "\n",
    "Жёсткий дедлайн: 25.03.2024 23:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 15 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-09-em-Username.ipynb\n",
    "* Модули preprocessing.py, metrics.py, models.py, содержащие написанный вами код\n",
    "* Ссылки на посылки в Яндекс.Контест для всех функций и классов, которые вы реализовали\n",
    "\n",
    "Ссылка на Яндекс.Контест: https://contest.yandex.ru/contest/60281\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generative model of Labels, Abilities, and Difficulties (GLAD)\n",
    "\n",
    "В [семинаре 16](https://github.com/esokolov/ml-course-hse/blob/master/2022-spring/seminars/sem16-em.pdf) мы рассмотрели задачу восстановления истинной разметки по меткам от экспертов (которым мы не можем доверять в полной мере, более того, их предсказания могут расходиться).\n",
    "\n",
    "Рассмотрим следующую вероятностную модель:\n",
    "\n",
    "$$ p(L, Z | \\alpha, \\beta) = \\prod_{i=1}^{n} \\prod_{j=1}^m \\sigma(\\alpha_j\\beta_i)^{[l_{ij}=z_i]}\\sigma(-\\alpha_j\\beta_i)^{1-[l_{ij}=z_i]} p(z_j)$$\n",
    "\n",
    "где $l_{ij} -$ ответ $j$-го эксперта на задачу $i$, $z_j -$ истинная разметка, $\\alpha_i, \\beta_j-$ уровень экспертизы и сложность задачи соответственно. Для более подробного описания модели можно прочитать материалы семинара, а также [оригинальную статью](http://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise.pdf). Априорное распределение положим равномерным: $p(z_i) = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "from os import listdir\n",
    "seed = 0xDEADF00D\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L = np.load('L.npy')\n",
    "n, m = L.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 1. (2 балла)** Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои. \n",
    "\n",
    "Обратите внимание, что правдоподобие моделирует не вероятность метки $l_{ij}$ принять значение 1 или 0, а вероятность того, что она равна скрытой переменной $z_i$, т.е. $p(l_{ij} = z_j|z_j, \\alpha_j, \\beta_i) \\neq p(l_{ij} = 1|\\alpha_j, \\beta_i) $. При этом заранее неизвестно, какая из скрытых переменных соответствует метке 1. Не забывайте, что параметры $\\beta_i$ должны быть неотрицательными; для этого оптимизируйте $\\log \\beta$. На M-шаге можете использовать как один шаг градиентного спуска, так и несколько: разумные результаты у вас должны получаться вне зависимости от числа итераций.\n",
    "\n",
    "Также при работе с вероятностями не забывайте о точности:\n",
    "1. Используйте логарифмы вероятностей.\n",
    "2. $\\log \\sigma(a)$ лучше преобразовать в $\\log \\sigma(a) = -\\log(1 + \\exp(-a)) = -\\mathrm{softplus}(-a) $\n",
    "3. Ещё полезные функции: `scipy.special.expit`, `scipy.special.logsumexp`, `np.log1p`\n",
    "\n",
    "Для отладки может быть полезно проверить градиент с помощью `scipy.optimize.check_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    '''stable version of log(1 + exp(x))'''\n",
    "    c = (x > 20) * 1.\n",
    "    return np.log1p(np.exp(x * (1-c)) * (1-c)) + x * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def posterior(alpha, beta, L):\n",
    "    \"\"\" Posterior over true labels z p(z|l, \\\\alpha, \\\\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def log_likelihood(alpha, beta, L, z):\n",
    "    \"\"\" p(l=z|z, \\\\alpha, \\\\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        z: ndarray of shape (n_problems).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def alpha_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def logbeta_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def lower_bound(alpha, beta, L, q):\n",
    "    \"\"\" Lower bound\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts).\n",
    "        beta: ndarray of shape (n_problems).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class math_module():\n",
    "    def iv_notation(x, y, method='equal'):\n",
    "        if method == 'equal':\n",
    "            return int(x == y)\n",
    "        else:\n",
    "            return int(x != y)\n",
    "    def softmax(array, index=0):\n",
    "        return np.exp(array[index]) / sum(np.exp(array))\n",
    "    def sigmoid(x):\n",
    "        return ( 1 / ( 1 + np.exp(-x) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's connect the seminar and the lecture names together\n",
    "\n",
    "$$\\Theta = (\\alpha_j, \\beta_i)$$\n",
    "\n",
    "$q(z_i)$ distribution needs to be updated on E step\n",
    "\n",
    "$\\Theta $ needs to be updated on M step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha, logbeta = np.random.randn(m), np.random.randn(n)\n",
    "alpha_beta_matrix = np.outer(np.exp(logbeta), alpha)\n",
    "\n",
    "alpha_beta_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class binary_EM:\n",
    "    def __init__(self, L, n_steps=1000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            L: ndarray of shape (n_problems, n_experts).\n",
    "            n_steps: number of EM steps.\n",
    "            lr: const for stable division in the algorithm.\n",
    "        \"\"\"\n",
    "        self.n, self.m = L.shape\n",
    "        self.alpha, self.logbeta = (np.random.randn(self.m)), np.random.randn(self.n)\n",
    "        \n",
    "        self.q = np.ones((2, len(self.logbeta))) * 0.5\n",
    "        # let first row be 0 and second row be 1\n",
    "        self.n_steps = n_steps\n",
    "        self.L = L\n",
    "        # I will introduce some constants\n",
    "        self.log_p = np.log(1/2)\n",
    "\n",
    "    def L_by_alpha_grad(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Expectation gradient of alpha\n",
    "        return: np.array(20)\n",
    "        \"\"\"\n",
    "        alpha_beta_matrix = np.outer(np.exp(self.logbeta), self.alpha)\n",
    "        full_matrix = alpha_beta_matrix.copy()\n",
    "        alpha_beta_matrix[self.L != 0] *= -1\n",
    "        \n",
    "        # if L == 1 -> alpha*beta *= -1\n",
    "\n",
    "        logit_positive = math_module.sigmoid(alpha_beta_matrix)\n",
    "        logit_positive[self.L != 1] *= 0 # [l == 1]\n",
    "        logit_negative = math_module.sigmoid(full_matrix)\n",
    "        logit_negative[self.L != 0] *= 0 # [l == 0]\n",
    "\n",
    "        positive_case = (self.q[1] * self.logbeta) @ (logit_positive - logit_negative)\n",
    "        \n",
    "        logit_positive = math_module.sigmoid(-alpha_beta_matrix)\n",
    "        logit_positive[self.L != 0] *= 0 # [l == 0]\n",
    "        logit_negative = math_module.sigmoid(full_matrix)\n",
    "        logit_negative[self.L != 1] *= 0 # [l == 1]\n",
    "        \n",
    "        negative_case = (self.q[0] * self.logbeta) @ (logit_positive - logit_negative)\n",
    "        \n",
    "        return (positive_case + negative_case)\n",
    "\n",
    "    def L_by_beta_grad(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Expectation gradient of beta\n",
    "        return: np.array(2000)\n",
    "        \"\"\"\n",
    "        alpha_beta_matrix = np.outer(np.exp(self.logbeta), self.alpha)\n",
    "        full_matrix = alpha_beta_matrix.copy()\n",
    "\n",
    "        alpha_beta_matrix[self.L != 1] *= -1\n",
    "\n",
    "\n",
    "        logit_positive = math_module.sigmoid(alpha_beta_matrix)\n",
    "        logit_positive[self.L != 1] *= 0\n",
    "        logit_negative = math_module.sigmoid(full_matrix)\n",
    "        logit_negative[self.L != 0] *= 0\n",
    "\n",
    "        negative_case = ( (logit_positive - logit_negative) @ self.alpha ) * self.q[0]\n",
    "\n",
    "        logit_positive = math_module.sigmoid(-alpha_beta_matrix)\n",
    "        logit_positive[self.L != 0] *= 0\n",
    "        logit_negative = math_module.sigmoid(full_matrix)\n",
    "        logit_negative[self.L != 1] *= 0\n",
    "\n",
    "        positive_case = ( (logit_positive - logit_negative) @ self.alpha ) * self.q[1]\n",
    "\n",
    "\n",
    "        return (positive_case + negative_case)\n",
    "    \n",
    "    def E_step(self):\n",
    "        \"\"\" Update q() \"\"\"\n",
    "        # LET'S VECTORIZE\n",
    "        alpha_beta_matrix = np.outer(np.exp(self.logbeta), self.alpha)\n",
    "        # m by n (2000, 20)\n",
    "        # I work around positive class\n",
    "        alpha_beta_matrix[self.L != 1] *= -1\n",
    "\n",
    "        # softplus instead of sigmoid\n",
    "        gamma_0 = -softplus( alpha_beta_matrix ).sum(1) + self.log_p\n",
    "        gamma_1 = -softplus( -alpha_beta_matrix ).sum(1) + self.log_p\n",
    "\n",
    "        prob_0 = np.exp(gamma_0) / ( np.exp(gamma_0) + np.exp(gamma_1) + 10**(-10))\n",
    "        prob_1 = np.exp(gamma_1) / ( np.exp(gamma_0) + np.exp(gamma_1) + 10**(-10))\n",
    "\n",
    "        self.q = np.concatenate([[prob_0], [prob_1]], axis = 0)\n",
    "\n",
    "    def M_step(self, GD_steps, lr):\n",
    "        \"\"\" Use L_alpha and L_beta for update \"\"\"\n",
    "        for _ in range(GD_steps):\n",
    "            alpha_expectation = self.L_by_alpha_grad()\n",
    "            beta_expectation = self.L_by_beta_grad()\n",
    "            \n",
    "            self.alpha += lr * alpha_expectation\n",
    "            self.logbeta += lr * beta_expectation\n",
    "\n",
    "    def EM_algorithm(self, GD_steps=2, lr=1e-4):\n",
    "        # somehow with lr = 1e-3 and higher the machine won't converge\n",
    "        # lr for learning rate\n",
    "        for _ in range(self.n_steps):\n",
    "            self.E_step()\n",
    "            self.M_step(GD_steps, lr)\n",
    "        return self.alpha, np.exp(self.logbeta), self.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = binary_EM(L, n_steps=2000)\n",
    "alpha, beta, q = algo.EM_algorithm(lr=1e-4)\n",
    "# RuntimeWarning: overflow encountered in exp kills the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 2. (1 балл)** Загрузите настоящую разметку. Посчитайте `accuracy` разметки, полученной с помощью обычного голосования по большинству среди экспертов, и сравните его с качеством, полученным с помощью EM-алгоритма. Помните, что алгоритму не важно, какая метка 0, а какая 1, поэтому если получите качество <0.5, то просто поменяйте метки классов (не забудьте также поменять знак у $\\alpha$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = np.load('y.npy')\n",
    "# (∩ ￣ー￣)⊃ ✳✨✳✨✳✨✳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956\n",
      "0.956\n",
      "\n",
      "0.9565\n",
      "0.9565\n",
      "\n",
      "0.9535\n",
      "0.9535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    algo = binary_EM(L)\n",
    "    _, _, q = algo.EM_algorithm(lr=1e-4)\n",
    "    algorithm_array = np.round(q)\n",
    "    acc0 = accuracy_score(y, algorithm_array[0])\n",
    "    acc1 = accuracy_score(y, algorithm_array[1])\n",
    "    print( max([acc0, 1-acc0]) )\n",
    "    print( max([acc1, 1-acc1]) )\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_32460\\30148706.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  return ( 1 / ( 1 + np.exp(-x) ) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025\n",
      "0.5015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\AppData\\Local\\Temp\\ipykernel_32460\\30148706.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  return ( 1 / ( 1 + np.exp(-x) ) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5115\n",
      "0.503\n",
      "\n",
      "0.9015\n",
      "0.9015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    algo = binary_EM(L)\n",
    "    _, _, q = algo.EM_algorithm(lr=1e-3)\n",
    "    algorithm_array = np.round(q)\n",
    "    acc0 = accuracy_score(y, algorithm_array[0])\n",
    "    acc1 = accuracy_score(y, algorithm_array[1])\n",
    "    print( max([acc0, 1-acc0]) )\n",
    "    print( max([acc1, 1-acc1]) )\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что с le=1e-3 (ну и больше) возникает exp overflow, что приводит к факапу модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 20)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of EM(lr=1e-4) with real classes: 0.9535\n",
      "Score of voting with real classes: 0.904\n",
      "Score of EM(lr=1e-4) with voting: 0.9075\n"
     ]
    }
   ],
   "source": [
    "voting_pred = np.array(stats.mode(L, axis=1))[0]\n",
    "print(\"Score of EM(lr=1e-4) with real classes:\", accuracy_score(y, np.round(q[1])))\n",
    "print(\"Score of voting with real classes:\", accuracy_score(y, voting_pred))\n",
    "print(\"Score of EM(lr=1e-4) with voting:\", accuracy_score(np.round(q[1]), voting_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 3. (0.5 балла)** Попробуйте проинтерпретировать полученные коэфициенты $\\alpha$. Есть ли в выборке эксперты, которые намеренно голосуют неверно? Как это можно понять по альфам? Продемонстрируйте, что эксперты действительно чаще голосуют за неверный класс. Постройте график зависимости доли врено размеченных экспертом объектов от коэффициента $\\alpha$. Прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (∩ᄑ_ᄑ)⊃━☆ﾟ*･｡*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 4. (бонус, 2 балла)**  Как уже было замечено выше, модели не важно, какой класс 1, а какой 0. Скажем, если все эксперты оказались максимально противными и ставят метку с точностью наоборот, то у вас будет полная согласованность между экспертами, при этом невозможно понять правильно они разметили выборку или нет, смотря только на такую разметку. Чтобы избежать этого, можно включать в выборку вопрос с заведомо известным ответом, тогда вы сможете определить, ставит ли эксперт специально неверные метки.\n",
    "\n",
    "Чтобы обощить данную модель на случай заданий с заведомо известной меткой, достоточно не делать для них E-шаг, а всегда полагать апостериорное распределение вырожденным в истинном классе. Реализуйте данную модель и используйте истинную разметку *для нескольких* задач из обучения. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Выравнивание слов (Word Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "EM-алгоритм также применяют на практике для настройки параметров модели выравнивания слов, более сложные модификации которой используются в статистическом машинном переводе. Мы не будем подробно обсуждать применение word alignment для перевода и ограничимся следующей целью: пусть у нас есть параллельный корпус из предложений на исходном языке и их переводов на целевой язык (в этом задании используются английский и чешский соответственно). \n",
    "\n",
    "Первая задача — определить с помощью этого корпуса, как переводится каждое отдельное слово на целевом языке. Вторая задача — для произвольной пары из предложения и его перевода установить, переводом какого слова в исходном предложении является каждое слово в целевом предложении. Оказывается, у обеих задач существует элегантное и эффективное решение при введении правильной вероятностной модели: в этой части задания вам предстоит его реализовать и оценить результаты работы. Но обо всём по порядку :)\n",
    "\n",
    "---\n",
    "\n",
    "Перед тем, как заниматься машинным обучением, давайте разберёмся с данными и метриками в интересующей нас задаче. В ячейке ниже загружается и разархивируется параллельный английско-чешский корпус, в котором есть разметка выравнивания слов. Нетрудно заметить, что формат XML-файла, использованный его авторами, не вполне стандартный: нет готовой команды , которая позволила бы получить список пар предложений вместе с выравниваниями. Это значит, что нужно разобраться с форматом и написать парсер самостоятельно, используя встроенные средства Python, например, модуль [xml](https://docs.python.org/3.7/library/xml.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -q https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-1804/CzEnAli_1.0.tar.gz -O CzEnAli_1.0.tar.gz\n",
    "mkdir -p data\n",
    "tar -xzf CzEnAli_1.0.tar.gz -C data/\n",
    "head -n 20 data/merged_data/project_syndicate/project_syndicate_bacchetta1.wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание -2. (0.5 балла)** Реализуйте функцию `extract_sentences`, которая принимает на вход путь к файлу с XML-разметкой, используемой в этом датасете, и возвращает список параллельных предложений, а также список из «уверенных» (sure) и «возможных» (possible) пар выравниваний. Отправьте вашу реализацию в Яндекс.Контест, чтобы убедиться в её корректности; в следующей ячейке ноутбука соберите все пары размеченных предложений из датасета в два списка `all_sentences` (список `SentencePair`) и `all_targets` (список LabeledAlignment).\n",
    "\n",
    "Здесь и далее соблюдайте сигнатуры функций и пользуйтесь объявленными в модуле `preprocessing.py` классами для организации данных. Стоит заметить, что предложения уже токенизированы (даже отделена пунктуация), поэтому предобработку текстов совершать не нужно. Обратите внимание на формат хранения выравниваний: нумерация начинается с 1 (в таком виде и нужно сохранять), первым в паре идёт слово из англоязычного предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SentencePair(source=['Relationship', 'of', 'ICOs', 'and', 'ICBs', 'with', 'the', 'Fund'], target=['Vztah', 'mezinárodních', 'organizací', 'pro', 'suroviny', 'a', 'mezinárodních', 'subjektů', 'pro', 'suroviny', 'k', 'fondu']),\n",
       "  SentencePair(source=['The', 'facilities', 'of', 'the', 'Fund', \"'s\", 'first', 'account', 'shall', 'be', 'used', 'only', 'by', 'ICOs', 'established', 'to', 'implement', 'the', 'provisions', 'of', 'ICAs', 'providing', 'for', 'either', 'international', 'buffer', 'stocks', 'or', 'internationally', 'coordinated', 'national', 'stocks', ',', 'and', 'which', 'have', 'concluded', 'an', 'association', 'agreement', '.'], target=['Prostředky', 'prvního', 'účtu', 'fondu', 'jsou', 'používány', 'pouze', 'mezinárodními', 'organizacemi', 'pro', 'suroviny', ',', 'které', 'jsou', 'zřízeny', 'za', 'účelem', 'provádění', 'mezinárodních', 'dohod', 'a', 'ujednání', 'o', 'surovinách', 'upravujících', 'mezinárodní', 'regulační', 'nebo', 'mezinárodně', 'koordinované', 'národní', 'sklady', ',', 'a', 'které', 'uzavřely', 'dohodu', 'o', 'přidružení', '.']),\n",
       "  SentencePair(source=['The', 'association', 'agreement', 'shall', 'comply', 'with', 'the', 'terms', 'of', 'this', 'Agreement', 'and', 'of', 'any', 'rules', 'and', 'regulations', 'consistent', 'therewith', 'to', 'be', 'adopted', 'by', 'the', 'governing', 'council', '.'], target=['Dohoda', 'o', 'přidružení', 'musí', 'být', 'v', 'souladu', 's', 'touto', 'dohodou', 'a', 's', 'pravidly', ',', 'která', 'neodporují', 'této', 'dohodě', 'a', 'která', 'přijme', 'rada', 'guvernérů', '.']),\n",
       "  SentencePair(source=['An', 'ICO', 'established', 'to', 'implement', 'the', 'provisions', 'of', 'an', 'ICA', 'which', 'provides', 'for', 'international', 'buffer', 'stocks', 'may', 'become', 'associated', 'with', 'the', 'Fund', 'for', 'the', 'purposes', 'of', 'the', 'first', 'account', ',', 'provided', 'that', 'the', 'ICA', 'is', 'negotiated', 'or', 'renegotiated', 'on', ',', 'and', 'conforms', 'to', ',', 'the', 'principle', 'of', 'joint', 'buffer', 'stock', 'financing', 'by', 'producers', 'and', 'consumers', 'participating', 'therein', '.'], target=['Mezinárodní', 'organizace', 'pro', 'suroviny', 'zřízená', 'za', 'účelem', 'provádění', 'mezinárodní', 'dohody', 'nebo', 'mezinárodního', 'ujednání', 'o', 'surovinách', ',', 'jež', 'upravuje', 'mezinárodní', 'regulační', 'nebo', 'mezinárodně', 'koordinované', 'národní', 'sklady', ',', 'se', 'může', 'přidružit', 'k', 'fondu', 'pro', 'účely', 'prvního', 'účtu', 'za', 'předpokladu', ',', 'že', 'mezinárodní', 'dohoda', 'nebo', 'ujednání', 'o', 'surovinách', 'je', 'sjednáno', 'v', 'souladu', 'se', 'zásadou', 'společného', 'financování', 'nárazových', 'zásob', 'zúčastněnými', 'výrobci', 'a', 'spotřebiteli', '.']),\n",
       "  SentencePair(source=['For', 'the', 'purposes', 'of', 'this', 'Agreement', ',', 'levy', '-', 'financed', 'ICAs', 'shall', 'be', 'eligible', 'for', 'association', 'with', 'the', 'Fund', '.'], target=['Pro', 'účely', 'této', 'dohody', 'se', 'mohou', 'mezinárodní', 'dohody', 'nebo', 'ujednání', 'o', 'surovinách', 'financované', 'z', 'poplatků', 'přidružit', 'k', 'fondu', '.']),\n",
       "  SentencePair(source=['A', 'proposed', 'association', 'agreement', 'shall', 'be', 'presented', 'by', 'the', 'managing', 'director', 'to', 'the', 'executive', 'board', 'and', ',', 'with', 'the', 'recommendation', 'of', 'the', 'board', ',', 'to', 'the', 'governing', 'council', 'for', 'approval', 'by', 'a', 'qualified', 'majority', '.'], target=['Návrh', 'dohody', 'o', 'přidružení', 'předloží', 'generální', 'ředitel', 'správní', 'radě', 'a', 's', 'jejím', 'doporučením', 'radě', 'guvernérů', 'ke', 'schválení', 'kvalifikovanou', 'většinou', '.']),\n",
       "  SentencePair(source=['In', 'carrying', 'out', 'the', 'provisions', 'of', 'the', 'association', 'agreement', 'between', 'the', 'Fund', 'and', 'an', 'associated', 'ICO', 'each', 'institution', 'shall', 'respect', 'the', 'autonomy', 'of', 'the', 'other', '.'], target=['Při', 'provádění', 'dohody', 'o', 'přidružení', 'mezi', 'fondem', 'a', 'přidruženou', 'mezinárodní', 'organizací', 'pro', 'suroviny', 'respektují', 'obě', 'instituce', 'vzájemně', 'svou', 'nezávislost', '.']),\n",
       "  SentencePair(source=['The', 'association', 'agreement', 'shall', 'specify', 'the', 'mutual', 'rights', 'and', 'obligations', 'of', 'the', 'Fund', 'and', 'the', 'associated', 'ICO', ',', 'in', 'terms', 'consistent', 'with', 'the', 'relevant', 'provisions', 'of', 'this', 'agreement', '.'], target=['Dohoda', 'o', 'přidružení', 'blíže', 'určí', 'vzájemná', 'práva', 'a', 'povinnosti', 'fondu', 'a', 'přidružené', 'mezinárodní', 'organizace', 'pro', 'suroviny', ',', 'a', 'to', 'v', 'souladu', 's', 'odpovídajícími', 'ustanoveními', 'této', 'dohody', '.']),\n",
       "  SentencePair(source=['An', 'associated', 'ICO', 'shall', 'be', 'entitled', 'to', 'borrow', 'from', 'the', 'Fund', 'through', 'its', 'first', 'account', 'without', 'prejudice', 'to', 'its', 'eligibility', 'to', 'obtain', 'financing', 'from', 'the', 'second', 'account', ',', 'provided', 'that', 'the', 'associated', 'ICO', 'and', 'its', 'participants', 'have', 'performed', 'and', 'are', 'duly', 'performing', 'their', 'obligations', 'to', 'the', 'Fund', '.'], target=['Přidružená', 'mezinárodní', 'organizace', 'pro', 'suroviny', 'je', 'oprávněná', 'půjčit', 'si', 'prostředky', 'z', 'prvního', 'účtu', 'fondu', ';', 'tím', 'není', 'dotčena', 'možnost', 'obdržet', 'financování', 'z', 'druhého', 'účtu', 'za', 'podmínky', ',', 'že', 'tato', 'organizace', 'a', 'její', 'účastníci', 'plnili', 'a', 'náležitě', 'plní', 'své', 'závazky', 'vůči', 'fondu', '.']),\n",
       "  SentencePair(source=['An', 'association', 'agreement', 'shall', 'provide', 'for', 'a', 'settlement', 'of', 'accounts', 'between', 'the', 'associated', 'ICO', 'and', 'the', 'Fund', 'before', 'any', 'renewal', 'of', 'the', 'association', 'agreement', '.'], target=['Dohoda', 'o', 'přidružení', 'upraví', 'vypořádání', 'účtů', 'mezi', 'přidruženou', 'mezinárodní', 'organizací', 'pro', 'suroviny', 'a', 'fondem', 'před', 'obnovením', 'takové', 'dohody', '.']),\n",
       "  SentencePair(source=['An', 'associated', 'ICO', 'may', ',', 'if', 'the', 'association', 'agreement', 'so', 'provides', 'and', 'with', 'the', 'consent', 'of', 'the', 'preceding', 'associated', 'ICO', 'covering', 'the', 'same', 'commodity', ',', 'succeed', 'to', 'the', 'rights', 'and', 'obligations', 'of', 'the', 'preceding', 'associated', 'ICO', '.'], target=['Jestliže', 'to', 'dohoda', 'o', 'přidružení', 'stanoví', 'a', 'jestliže', 'předchozí', 'mezinárodní', 'organizace', 'pro', 'suroviny', 'přidružená', 'pro', 'stejnou', 'surovinu', 's', 'tím', 'vysloví', 'souhlas', ',', 'může', 'přidružená', 'mezinárodní', 'organizace', 'pro', 'suroviny', 'vstoupit', 'do', 'práv', 'a', 'závazků', 'předchozí', 'organizace', '.']),\n",
       "  SentencePair(source=['The', 'Fund', 'shall', 'not', 'intervene', 'directly', 'in', 'commodity', 'markets', '.'], target=['Fond', 'neintervenuje', 'přímo', 'na', 'trzích', 'surovin', '.']),\n",
       "  SentencePair(source=['However', ',', 'the', 'Fund', 'may', 'dispose', 'of', 'commodity', 'stocks', 'only', 'pursuant', 'to', 'Article', '17', '(', '15', ')', 'to', '(', '17', ')', '.'], target=['Smí', 'nakládat', 'se', 'zásobami', 'surovin', 'pouze', 'na', 'základě', 'čl', '.', '17', 'odst', '.', '15', 'až', '17', '.']),\n",
       "  SentencePair(source=['For', 'the', 'purpose', 'of', 'the', 'second', 'account', ',', 'the', 'executive', 'board', 'shall', 'from', 'time', 'to', 'time', 'designate', 'appropriate', 'commodity', 'bodies', ',', 'including', 'ICOs', ',', 'whether', 'or', 'not', 'they', 'are', 'associated', 'ICOs', ',', 'as', 'ICBs', ',', 'provided', 'that', 'they', 'meet', 'the', 'criteria', 'set', 'out', 'in', 'schedule', 'C', '.'], target=['Pro', 'účely', 'druhého', 'účtu', 'správní', 'rada', 'případně', 'ustanoví', 'vhodné', 'subjekty', 'pro', 'suroviny', 'včetně', 'mezinárodních', 'organizací', 'pro', 'suroviny', ',', 'přidružených', 'či', 'nikoli', ',', 'mezinárodními', 'subjekty', 'pro', 'suroviny', 'za', 'podmínky', ',', 'že', 'splňují', 'kritéria', 'stanovená', 'v', 'příloze', 'C', '.']),\n",
       "  SentencePair(source=['Unit', 'of', 'account', 'and', 'currencies'], target=['Zúčtovací', 'jednotka', 'a', 'měny']),\n",
       "  SentencePair(source=['The', 'unit', 'of', 'account', 'of', 'the', 'Fund', 'shall', 'be', 'as', 'defined', 'in', 'schedule', 'F', '.'], target=['Zúčtovací', 'jednotka', 'fondu', 'je', 'vymezena', 'v', 'příloze', 'F', '.']),\n",
       "  SentencePair(source=['The', 'Fund', 'shall', 'hold', ',', 'and', 'conduct', 'its', 'financial', 'transactions', 'in', ',', 'usable', 'currencies', '.'], target=['Fond', 'drží', 'použitelné', 'měny', 'a', 'provádí', 'v', 'nich', 'finanční', 'transakce', '.']),\n",
       "  SentencePair(source=['Except', 'as', 'provided', 'in', 'Article', '16', '(', '5', ')', '(', 'b', ')', ',', 'no', 'Member', 'shall', 'maintain', 'or', 'impose', 'restrictions', 'on', 'the', 'holding', ',', 'use', 'or', 'exchange', 'by', 'the', 'Fund', 'of', 'usable', 'currencies', 'deriving', 'from', ':'], target=['S', 'výhradou', 'čl', '.', '16', 'odst', '.', '5', 'písm', '.', 'b', ')', 'žádný', 'člen', 'neudržuje', 'ani', 'nezavádí', 'omezení', 'toho', ',', 'aby', 'fond', 'držel', ',', 'používal', 'nebo', 'směňoval', 'použitelné', 'měny', 'pocházející', 'z', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', 'Payment', 'of', 'subscriptions', 'of', 'shares', 'of', 'directly', 'contributed', 'capital', ';'], target=['a', ')', 'plateb', 'za', 'upsání', 'akcií', 'přímo', 'splaceného', 'kapitálu', ';']),\n",
       "  SentencePair(source=['(', 'b', ')', 'Payment', 'of', 'guarantee', 'capital', ',', 'cash', 'in', 'lieu', 'of', 'guarantee', 'capital', ',', 'guarantees', 'or', 'cash', 'deposits', 'resulting', 'from', 'the', 'association', 'of', 'ICOs', 'with', 'the', 'Fund', ';'], target=['b', ')', 'plateb', 'záručního', 'kapitálu', ',', 'hotovosti', 'namísto', 'záručního', 'kapitálu', ',', 'záruk', 'nebo', 'vkladů', 'v', 'hotovosti', 'plynoucích', 'z', 'přidružení', 'mezinárodní', 'organizace', 'pro', 'suroviny', 'k', 'fondu', ';']),\n",
       "  SentencePair(source=['(', 'c', ')', 'Payment', 'of', 'voluntary', 'contributions', ';'], target=['c', ')', 'plateb', 'dobrovolných', 'příspěvků', ';']),\n",
       "  SentencePair(source=['(', 'd', ')', 'Borrowing', ';'], target=['d', ')', 'půjček', ';']),\n",
       "  SentencePair(source=['(', 'e', ')', 'Disposal', 'of', 'forfeited', 'stocks', ',', 'pursuant', 'to', 'Article', '17', '(', '15', ')', 'to', '(', '17', ')', ';'], target=['e', ')', 'zcizení', 'propadlých', 'zásob', 'podle', 'čl', '.', '17', 'odst', '.', '15', 'až', '17', ';']),\n",
       "  SentencePair(source=['(', 'f', ')', 'Payment', 'on', 'account', 'of', 'principal', ',', 'income', ',', 'interest', 'or', 'other', 'charges', 'in', 'respect', 'of', 'loans', 'or', 'investments', 'made', 'out', 'of', 'any', 'of', 'the', 'funds', 'referred', 'to', 'in', 'this', 'paragraph', '.'], target=['f', ')', 'plateb', 'na', 'jistinu', ',', 'příjmů', ',', 'úroků', 'nebo', 'jiných', 'poplatků', 'z', 'půjček', 'nebo', 'investic', 'provedených', 'z', 'prostředků', 'uvedených', 'v', 'tomto', 'odstavci', '.']),\n",
       "  SentencePair(source=['The', 'executive', 'board', 'shall', 'determine', 'the', 'method', 'of', 'valuation', 'of', 'usable', 'currencies', ',', 'in', 'terms', 'of', 'the', 'unit', 'of', 'account', ',', 'in', 'accordance', 'with', 'prevailing', 'international', 'monetary', 'practice', '.'], target=['Správní', 'rada', 'určí', 'metodu', 'ohodnocení', 'použitelných', 'měn', 'vyjádřených', 've', 'zúčtovací', 'jednotce', 'v', 'souladu', 's', 'stávající', 'mezinárodní', 'měnovou', 'praxí', '.']),\n",
       "  SentencePair(source=['Capital', 'resources'], target=['Kapitálové', 'zdroje']),\n",
       "  SentencePair(source=['The', 'capital', 'of', 'the', 'Fund', 'shall', 'consist', 'of', ':'], target=['Kapitál', 'fondu', 'se', 'skládá']),\n",
       "  SentencePair(source=['(', 'a', ')', 'Directly', 'contributed', 'capital', 'to', 'be', 'divided', 'into', '47', '000', 'shares', 'to', 'be', 'issued', 'by', 'the', 'Fund', ',', 'having', 'a', 'par', 'value', 'of', '7', '566', ',', '47145', 'units', 'of', 'account', 'each', 'and', 'a', 'total', 'value', 'of', '355', '624', '158', 'units', 'of', 'account', ';', 'and'], target=['a', ')', 'z', 'přímo', 'splaceného', 'kapitálu', 'rozděleného', 'na', '47000', 'akcií', ',', 'které', 'vydá', 'fond', ',', 'z', 'nichž', 'každá', 'má', 'nominální', 'hodnotu', '7566,47145', 'zúčtovacích', 'jednotek', 'a', 'kdy', 'celková', 'hodnota', 'činí', '355624158', 'zúčtovacích', 'jednotek', ',', 'a']),\n",
       "  SentencePair(source=['(', 'b', ')', 'Guarantee', 'capital', 'provided', 'directly', 'to', 'the', 'Fund', 'in', 'accordance', 'with', 'Article', '14', '(', '4', ')', '.'], target=['b', ')', 'ze', 'záručního', 'kapitálu', 'přímo', 'poskytnutého', 'fondu', 'v', 'souladu', 's', 'čl', '.', '14', 'odst', '.', '4', '.']),\n",
       "  SentencePair(source=['The', 'shares', 'to', 'be', 'issued', 'by', 'the', 'Fund', 'shall', 'be', 'divided', 'into', ':'], target=['Akcie', 'vydané', 'fondem', 'se', 'rozdělí', 'na', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', '37', '000', 'paid', '-', 'in', 'shares', ';', 'and'], target=['a', ')', '37000', 'splacených', 'akcií', ';']),\n",
       "  SentencePair(source=['(', 'b', ')', '10', '000', 'payable', 'shares', '.'], target=['b', ')', '10000', 'nesplacených', 'akcií', '.']),\n",
       "  SentencePair(source=['Shares', 'of', 'directly', 'contributed', 'capital', 'shall', 'be', 'available', 'for', 'subscription', 'only', 'by', 'Members', 'in', 'accordance', 'with', 'the', 'provisions', 'of', 'Article', '10', '.'], target=['Akcie', 'přímo', 'splaceného', 'kapitálu', 'mohou', 'upisovat', 'pouze', 'členové', 'v', 'souladu', 's', 'článkem', '10', '.']),\n",
       "  SentencePair(source=['The', 'shares', 'of', 'directly', 'contributed', 'capital', ':'], target=['Počet', 'akcií', 'přímo', 'splaceného', 'kapitálu', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', 'Shall', ',', 'if', 'necessary', ',', 'be', 'increased', 'by', 'the', 'governing', 'council', 'upon', 'the', 'accession', 'of', 'any', 'State', 'under', 'Article', '56', ';'], target=['a', ')', 'je', 'v', 'případě', 'potřeby', 'zvýšen', 'radou', 'guvernérů', 'po', 'přistoupení', 'státu', 'podle', 'článku', '56', ';']),\n",
       "  SentencePair(source=['(', 'b', ')', 'May', 'be', 'increased', 'by', 'the', 'governing', 'council', 'in', 'accordance', 'with', 'Article', '12', ';'], target=['b', ')', 'může', 'být', 'zvýšen', 'radou', 'guvernérů', 'podle', 'článku', '12', ';']),\n",
       "  SentencePair(source=['(', 'c', ')', 'Shall', 'be', 'increased', 'by', 'the', 'amount', 'needed', 'pursuant', 'to', 'Article', '17', '(', '14', ')', '.'], target=['c', ')', 'se', 'zvýší', 'o', 'potřebnou', 'částku', 'podle', 'čl', '.', '17', 'odst', '.', '14', '.']),\n",
       "  SentencePair(source=['If', 'the', 'governing', 'council', 'makes', 'available', 'for', 'subscription', 'the', 'unsubscribed', 'shares', 'of', 'directly', 'contributed', 'capital', 'pursuant', 'to', 'Article', '12', '(', '3', ')', 'or', 'increases', 'the', 'shares', 'of', 'directly', 'contributed', 'capital', 'pursuant', 'to', 'paragraph', '4', '(', 'b', ')', 'or', '4', '(', 'c', ')', 'of', 'this', 'Article', ',', 'each', 'Member', 'shall', 'have', 'the', 'right', ',', 'but', 'shall', 'not', 'be', 'required', ',', 'to', 'subscribe', 'such', 'shares', '.'], target=['Jestliže', 'rada', 'guvernérů', 'nabídne', 'k', 'upisování', 'neupsané', 'akcie', 'přímo', 'splaceného', 'kapitálu', 'podle', 'čl', '.', '12', 'odst', '.', '3', 'nebo', 'zvýší', 'počet', 'akcií', 'přímo', 'splaceného', 'kapitálu', 'podle', 'odst', '.', '4', 'písm', '.', 'b', ')', 'nebo', 'c', ')', ',', 'má', 'každý', 'člen', 'právo', ',', 'nikoli', 'však', 'povinnost', ',', 'na', 'upsání', 'těchto', 'akcií', '.']),\n",
       "  SentencePair(source=['Subscription', 'of', 'shares'], target=['Upisování', 'akcií']),\n",
       "  SentencePair(source=['Each', 'Member', 'referred', 'to', 'in', 'Article', '5', '(', 'a', ')', 'shall', 'subscribe', ',', 'as', 'set', 'forth', 'in', 'schedule', 'A', ':'], target=['Každý', 'člen', 'uvedený', 'v', 'čl', '.', '5', 'písm', '.', 'a', ')', 'upíše', 'v', 'souladu', 's', 'přílohou', 'A', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', '100', 'paid', '-', 'in', 'shares', ';', 'and'], target=['a', ')', '100', 'splacených', 'akcií', 'a']),\n",
       "  SentencePair(source=['(', 'b', ')', 'Any', 'additional', 'paid', '-', 'in', 'and', 'payable', 'shares', '.'], target=['b', ')', 'další', 'splacené', 'a', 'nesplacené', 'akcie', '.']),\n",
       "  SentencePair(source=['Each', 'Member', 'referred', 'to', 'in', 'Article', '5', '(', 'b', ')', 'shall', 'subscribe', ':'], target=['Každý', 'člen', 'uvedený', 'v', 'čl', '.', '5', 'písm', '.', 'b', ')', 'upíše', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', '100', 'paid', '-', 'in', 'shares', ';', 'and'], target=['a', ')', '100', 'splacených', 'akcií', 'a']),\n",
       "  SentencePair(source=['(', 'b', ')', 'Any', 'additional', 'paid', '-', 'in', 'and', 'payable', 'shares', 'to', 'be', 'determined', 'by', 'the', 'governing', 'council', 'by', 'a', 'qualified', 'majority', 'in', 'a', 'manner', 'consistent', 'with', 'the', 'allocation', 'of', 'shares', 'in', 'schedule', 'A', 'and', 'in', 'accordance', 'with', 'the', 'terms', 'and', 'conditions', 'agreed', 'pursuant', 'to', 'Article', '56', '.'], target=['b', ')', 'další', 'splacené', 'a', 'nesplacené', 'akcie', 'určené', 'radou', 'guvernérů', 'kvalifikovanou', 'většinou', ',', 'a', 'to', 'způsobem', 'odpovídajícím', 'rozdělení', 'akcií', 'podle', 'přílohy', 'A', 'a', 'v', 'souladu', 's', 'podmínkami', 'dohodnutými', 'podle', 'článku', '56', '.']),\n",
       "  SentencePair(source=['Each', 'Member', 'may', 'allocate', 'to', 'the', 'second', 'account', 'a', 'part', 'of', 'its', 'subscription', 'under', 'paragraph', '1', '(', 'a', ')', 'of', 'this', 'Article', 'with', 'a', 'view', 'to', 'an', 'aggregate', 'allocation', 'to', 'the', 'second', 'account', 'on', 'a', 'voluntary', 'basis', ',', 'of', 'not', 'less', 'than', '52', '965', '300', 'units', 'of', 'account', '.'], target=['Každý', 'člen', 'může', 'přidělit', 'na', 'druhý', 'účet', 'část', 'svých', 'upsaných', 'akcií', 'podle', 'odst', '.', '1', 'písm', '.', 'a', ')', ',', 'přičemž', 'celková', 'výše', 'dobrovolného', 'přídělu', 'na', 'druhý', 'účet', 'nesmí', 'být', 'nižší', 'než', '52965300', 'zúčtovacích', 'jednotek', '.']),\n",
       "  SentencePair(source=['Shares', 'of', 'directly', 'contributed', 'capital', 'shall', 'not', 'be', 'pledged', 'or', 'encumbered', 'by', 'Members', 'in', 'any', 'manner', 'whatsoever', 'and', 'shall', 'be', 'transferable', 'only', 'to', 'the', 'Fund', '.'], target=['Akcie', 'přímo', 'splaceného', 'kapitálu', 'nesmějí', 'být', 'členy', 'zastavovány', 'ani', 'zatěžovány', 'a', 'mohou', 'být', 'převedeny', 'pouze', 'na', 'fond', '.']),\n",
       "  SentencePair(source=['Payment', 'of', 'shares'], target=['Splacení', 'akcií']),\n",
       "  SentencePair(source=['Payments', 'of', 'shares', 'of', 'directly', 'contributed', 'capital', 'subscribed', 'by', 'each', 'Member', 'shall', 'be', 'made', ':'], target=['Splacení', 'akcií', 'přímo', 'splaceného', 'kapitálu', ',', 'které', 'upisuje', 'každý', 'člen', ',', 'se', 'provádí', 'v', ':']),\n",
       "  SentencePair(source=['(', 'a', ')', 'In', 'any', 'usable', 'currency', 'at', 'the', 'rate', 'of', 'conversion', 'between', 'that', 'usable', 'currency', 'and', 'the', 'unit', 'of', 'account', 'as', 'at', 'the', 'date', 'of', 'payment', ';', 'or'], target=['a', ')', 'použitelné', 'měně', 'v', 'přepočítacím', 'koeficientu', 'mezi', 'touto', 'měnou', 'a', 'zúčtovací', 'jednotkou', 'platném', 'v', 'den', 'platby', ',', 'nebo'])],\n",
       " [LabeledAlignment(sure=[(1, 1), (3, 2), (3, 3), (3, 4), (3, 5), (4, 6), (5, 10), (5, 7), (5, 8), (5, 9), (6, 11), (8, 12)], possible=[(2, 3), (7, 12)]),\n",
       "  LabeledAlignment(sure=[(10, 5), (11, 6), (12, 7), (14, 10), (14, 11), (14, 8), (14, 9), (15, 15), (16, 16), (16, 17), (2, 1), (21, 19), (21, 20), (21, 21), (21, 22), (21, 23), (21, 24), (22, 25), (25, 26), (26, 27), (28, 28), (29, 29), (30, 30), (31, 31), (32, 32), (33, 33), (34, 34), (35, 35), (37, 36), (39, 39), (40, 37), (41, 40), (5, 4), (7, 2), (8, 3), (9, 5)], possible=[(1, 1), (13, 9), (15, 12), (15, 13), (15, 14), (17, 18), (18, 18), (19, 18), (20, 20), (23, 25), (24, 28), (3, 3), (3, 4), (36, 36), (38, 37), (39, 38), (4, 3), (4, 4), (6, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 9), (11, 10), (12, 11), (13, 12), (15, 13), (2, 3), (22, 21), (25, 23), (26, 22), (27, 24), (3, 1), (4, 4), (5, 5), (5, 6), (5, 7), (6, 8)], possible=[(1, 1), (14, 13), (18, 16), (19, 17), (2, 2), (20, 21), (21, 21), (23, 21), (23, 22), (24, 22)]),\n",
       "  LabeledAlignment(sure=[(10, 10), (10, 14), (10, 15), (10, 9), (11, 17), (12, 18), (14, 19), (15, 20), (16, 25), (17, 28), (18, 29), (19, 29), (2, 1), (2, 2), (2, 3), (2, 4), (20, 30), (22, 31), (23, 32), (25, 33), (28, 34), (29, 35), (3, 5), (31, 36), (31, 37), (32, 39), (34, 40), (34, 41), (34, 44), (34, 45), (35, 46), (36, 47), (4, 6), (4, 7), (42, 49), (43, 50), (46, 51), (48, 52), (49, 54), (5, 8), (50, 55), (51, 53), (53, 57), (54, 58), (55, 59), (56, 56), (58, 60)], possible=[(1, 2), (10, 11), (10, 12), (10, 13), (11, 16), (13, 18), (19, 27), (21, 31), (24, 33), (26, 34), (26, 35), (27, 34), (27, 35), (30, 37), (32, 38), (33, 41), (34, 42), (34, 43), (42, 48), (45, 51), (47, 52), (47, 53), (52, 57), (57, 56), (9, 10)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 13), (11, 11), (11, 12), (11, 7), (11, 8), (16, 16), (17, 17), (19, 18), (20, 19), (3, 2), (5, 3), (6, 4), (8, 15)], possible=[(11, 10), (11, 9), (12, 6), (13, 6), (14, 6), (15, 16), (16, 5), (18, 18), (2, 2), (4, 4), (8, 14), (9, 15)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 7), (14, 8), (15, 9), (16, 10), (18, 11), (2, 1), (20, 13), (27, 15), (28, 14), (29, 16), (3, 4), (30, 17), (33, 18), (34, 19), (35, 20), (4, 2), (7, 5)], possible=[(1, 1), (1, 2), (12, 9), (13, 9), (19, 13), (25, 14), (26, 14), (3, 3), (31, 18), (31, 19), (32, 19), (5, 5), (6, 5), (8, 5), (8, 7), (9, 7)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 6), (12, 7), (13, 8), (15, 9), (16, 10), (16, 11), (16, 12), (16, 13), (17, 15), (18, 16), (2, 2), (20, 14), (22, 19), (26, 20), (3, 2), (8, 5), (9, 3)], possible=[(11, 7), (14, 11), (14, 9), (19, 14), (21, 18), (21, 19), (23, 17), (24, 17), (25, 17), (6, 3), (6, 4), (7, 3), (8, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 9), (13, 10), (14, 11), (16, 12), (17, 13), (17, 14), (17, 15), (17, 16), (18, 17), (2, 3), (21, 21), (22, 22), (24, 23), (25, 24), (27, 25), (28, 26), (29, 27), (3, 1), (5, 4), (5, 5), (7, 6), (8, 7), (9, 8)], possible=[(1, 1), (11, 10), (12, 10), (15, 14), (19, 20), (2, 2), (20, 21), (21, 20), (23, 24), (26, 26), (4, 5), (6, 7)]),\n",
       "  LabeledAlignment(sure=[(11, 14), (14, 12), (15, 13), (16, 17), (17, 18), (2, 1), (20, 19), (22, 20), (23, 21), (24, 22), (26, 23), (27, 24), (29, 25), (29, 26), (3, 2), (3, 3), (3, 4), (3, 5), (30, 28), (31, 29), (34, 31), (35, 32), (36, 33), (38, 34), (39, 35), (41, 36), (42, 37), (43, 38), (44, 39), (45, 40), (47, 41), (48, 42), (5, 6), (6, 7), (8, 8)], possible=[(1, 3), (10, 14), (12, 10), (15, 11), (16, 16), (16, 18), (17, 16), (17, 17), (18, 16), (18, 17), (18, 18), (21, 20), (25, 23), (25, 24), (28, 26), (30, 27), (33, 30), (37, 34), (4, 6), (40, 37), (46, 41), (7, 8), (8, 9), (9, 11), (9, 14)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 7), (13, 8), (14, 10), (14, 11), (14, 12), (14, 9), (15, 13), (17, 14), (18, 15), (2, 3), (20, 16), (22, 17), (24, 18), (25, 19), (3, 1), (5, 4), (8, 5)], possible=[(1, 1), (12, 10), (16, 14), (19, 16), (2, 2), (21, 18), (4, 4), (6, 4), (6, 5), (7, 5), (9, 6)]),\n",
       "  LabeledAlignment(sure=[(10, 2), (11, 6), (12, 7), (15, 21), (18, 9), (19, 14), (2, 24), (20, 10), (20, 11), (20, 12), (20, 13), (23, 16), (24, 17), (25, 22), (26, 29), (27, 30), (29, 31), (3, 25), (3, 26), (3, 27), (3, 28), (30, 32), (31, 33), (34, 34), (37, 36), (4, 23), (6, 1), (8, 5), (9, 3)], possible=[(1, 26), (14, 21), (15, 20), (16, 9), (17, 9), (22, 16), (22, 17), (28, 31), (32, 34), (32, 35), (33, 34), (33, 35), (36, 35), (7, 3), (8, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 7), (2, 1), (4, 2), (5, 2), (6, 3), (7, 4), (8, 6), (9, 5)], possible=[(1, 1), (3, 2)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 7), (11, 8), (13, 9), (14, 11), (16, 14), (18, 15), (20, 16), (22, 17), (5, 1), (6, 2), (7, 3), (8, 5), (9, 4)], possible=[(12, 8), (13, 10), (15, 14), (17, 14), (19, 16), (21, 16)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 5), (11, 6), (17, 8), (18, 9), (19, 12), (20, 10), (22, 13), (23, 14), (23, 15), (23, 16), (23, 17), (24, 18), (26, 20), (27, 21), (3, 2), (30, 19), (36, 27), (36, 28), (37, 30), (39, 31), (41, 32), (42, 33), (43, 33), (44, 34), (45, 35), (46, 36), (47, 37), (6, 3), (7, 4)], possible=[(12, 8), (13, 7), (14, 7), (15, 7), (16, 7), (19, 11), (2, 2), (21, 13), (28, 19), (29, 19), (31, 23), (31, 24), (31, 25), (31, 26), (32, 22), (33, 24), (34, 23), (34, 24), (34, 25), (34, 26), (35, 28), (37, 29), (38, 31), (4, 4), (40, 32), (5, 4), (9, 6)]),\n",
       "  LabeledAlignment(sure=[(1, 2), (3, 1), (4, 3), (5, 4)], possible=[(2, 1)]),\n",
       "  LabeledAlignment(sure=[(11, 5), (12, 6), (13, 7), (14, 8), (15, 9), (2, 2), (4, 1), (7, 3), (9, 4)], possible=[(1, 2), (10, 5), (3, 1), (5, 3), (6, 3), (8, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 10), (13, 3), (14, 4), (15, 11), (2, 1), (4, 2), (6, 5), (7, 6), (9, 9)], possible=[(1, 1), (11, 7), (11, 8), (3, 2), (5, 5)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (1, 2), (11, 11), (12, 12), (14, 13), (15, 14), (17, 15), (18, 16), (20, 18), (23, 23), (25, 25), (26, 26), (27, 27), (32, 28), (33, 29), (34, 30), (35, 31), (36, 32), (5, 3), (6, 5), (8, 8)], possible=[(14, 15), (14, 17), (16, 15), (19, 17), (21, 23), (22, 23), (24, 24), (28, 22), (29, 21), (29, 22), (30, 21), (30, 22), (31, 29), (5, 4), (7, 8), (9, 8)]),\n",
       "  LabeledAlignment(sure=[(10, 7), (11, 8), (12, 9), (13, 10), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (8, 6)], possible=[(7, 6), (9, 9)]),\n",
       "  LabeledAlignment(sure=[(10, 8), (11, 8), (13, 9), (14, 10), (15, 11), (16, 12), (17, 13), (18, 16), (19, 14), (2, 1), (20, 17), (21, 18), (23, 19), (25, 20), (25, 21), (25, 22), (25, 23), (26, 24), (28, 25), (29, 26), (3, 2), (4, 3), (6, 4), (7, 5), (8, 6), (9, 7)], possible=[(12, 10), (18, 15), (22, 19), (24, 21), (27, 25), (5, 5)]),\n",
       "  LabeledAlignment(sure=[(2, 1), (3, 2), (4, 3), (6, 4), (7, 5), (8, 6)], possible=[(5, 5)]),\n",
       "  LabeledAlignment(sure=[(2, 1), (3, 2), (4, 3), (5, 4)], possible=[()]),\n",
       "  LabeledAlignment(sure=[(11, 7), (12, 9), (14, 12), (16, 13), (18, 14), (2, 1), (20, 15), (3, 2), (4, 3), (6, 4), (7, 5), (9, 6)], possible=[(10, 6), (11, 8), (13, 12), (15, 12), (17, 14), (19, 14), (5, 5)]),\n",
       "  LabeledAlignment(sure=[(10, 7), (11, 8), (12, 9), (13, 10), (14, 11), (15, 12), (19, 14), (2, 1), (20, 15), (21, 16), (22, 17), (23, 17), (24, 18), (28, 19), (29, 20), (3, 2), (31, 21), (32, 22), (33, 23), (34, 24), (4, 3), (5, 4), (8, 5), (9, 6)], possible=[(18, 13), (25, 19), (26, 19), (27, 19), (30, 20), (6, 5), (7, 5)]),\n",
       "  LabeledAlignment(sure=[(11, 6), (12, 7), (15, 8), (16, 9), (18, 11), (2, 1), (20, 10), (22, 12), (23, 13), (24, 14), (25, 15), (26, 16), (27, 17), (28, 18), (29, 19), (3, 2), (5, 3), (7, 4), (9, 5)], possible=[(1, 2), (10, 7), (14, 8), (14, 9), (15, 9), (16, 8), (17, 11), (19, 10), (4, 3), (6, 4), (8, 5)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (2, 2)], possible=[()]),\n",
       "  LabeledAlignment(sure=[(2, 1), (5, 2), (7, 3), (7, 4)], possible=[(1, 1), (3, 2), (4, 2), (6, 4), (8, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 8), (11, 9), (12, 9), (13, 10), (16, 13), (19, 14), (2, 1), (21, 19), (24, 21), (26, 22), (27, 22), (28, 22), (29, 22), (3, 2), (30, 24), (32, 23), (33, 18), (34, 25), (36, 27), (37, 28), (39, 30), (4, 4), (40, 30), (41, 30), (42, 32), (44, 31), (45, 33), (46, 34), (5, 5), (6, 6), (9, 7)], possible=[(14, 13), (15, 13), (17, 14), (18, 14), (20, 15), (22, 21), (23, 20), (25, 21), (31, 23), (35, 28), (38, 29), (43, 31), (6, 3), (7, 7), (8, 7)]),\n",
       "  LabeledAlignment(sure=[(10, 8), (11, 9), (12, 10), (13, 11), (14, 12), (15, 14), (17, 17), (19, 18), (2, 1), (3, 2), (4, 4), (5, 5), (6, 7), (7, 6)], possible=[(14, 13), (16, 17), (18, 17), (4, 3), (8, 8), (9, 8)]),\n",
       "  LabeledAlignment(sure=[(11, 5), (12, 6), (13, 7), (2, 1), (5, 2), (8, 3)], possible=[(1, 1), (10, 5), (11, 4), (3, 2), (4, 2), (6, 3), (7, 3), (9, 5)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (2, 1), (3, 2), (4, 3), (5, 3), (6, 4), (8, 4), (9, 5)], possible=[(7, 4)]),\n",
       "  LabeledAlignment(sure=[(2, 1), (3, 2), (4, 3), (5, 3), (6, 4), (7, 5), (8, 6)], possible=[()]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 6), (11, 7), (13, 8), (14, 9), (15, 10), (16, 11), (20, 12), (21, 13), (22, 14), (3, 2), (4, 3), (5, 4), (6, 5)], possible=[(12, 8), (2, 3), (2, 4), (7, 5), (8, 5), (9, 6)]),\n",
       "  LabeledAlignment(sure=[(2, 2), (4, 3), (5, 4), (6, 5), (7, 6)], possible=[(1, 2), (3, 5)]),\n",
       "  LabeledAlignment(sure=[(10, 7), (13, 9), (14, 8), (15, 10), (17, 11), (2, 1), (20, 12), (21, 13), (22, 14), (23, 15), (24, 16), (3, 2)], possible=[(10, 3), (11, 8), (12, 8), (16, 11), (18, 12), (19, 12), (4, 3), (4, 7), (6, 4), (6, 5), (6, 6), (7, 4), (7, 5), (7, 6), (9, 3), (9, 7)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 8), (12, 8), (13, 8), (14, 9), (15, 10), (16, 11), (2, 1), (3, 2), (4, 3), (5, 4), (6, 5), (9, 7)], possible=[(7, 6), (8, 6)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 8), (13, 9), (14, 11), (16, 14), (18, 15), (2, 1), (3, 2), (6, 3), (6, 4), (7, 5), (9, 7)], possible=[(12, 8), (13, 10), (15, 14), (17, 14), (4, 4), (5, 4), (8, 7)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 7), (11, 8), (13, 9), (14, 10), (15, 11), (16, 12), (18, 13), (19, 15), (21, 18), (23, 19), (24, 20), (26, 22), (28, 23), (29, 24), (3, 3), (30, 25), (31, 26), (33, 27), (34, 29), (36, 32), (37, 33), (38, 34), (4, 2), (41, 35), (42, 36), (47, 39), (48, 40), (50, 38), (52, 41), (53, 42), (54, 44), (56, 43), (58, 45), (59, 46), (6, 4), (60, 47), (61, 48), (62, 49), (63, 50), (64, 51), (7, 5), (8, 6)], possible=[(12, 11), (17, 12), (18, 14), (2, 2), (20, 18), (22, 18), (25, 22), (27, 25), (32, 26), (33, 28), (46, 37), (49, 38), (5, 4), (51, 41), (55, 43), (57, 45), (9, 8)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (3, 2)], possible=[(2, 2)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 11), (12, 12), (18, 16), (19, 17), (2, 2), (20, 18), (3, 3), (5, 4), (6, 5), (7, 7), (9, 10)], possible=[(11, 12), (14, 13), (14, 14), (14, 15), (15, 13), (15, 14), (15, 15), (16, 13), (16, 14), (16, 15), (17, 13), (17, 14), (17, 15), (4, 3), (6, 6)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (2, 1), (3, 2), (4, 3), (5, 4), (7, 4), (8, 5)], possible=[(6, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 7), (12, 8), (2, 1), (3, 2), (5, 3), (6, 4), (8, 4), (9, 5)], possible=[(4, 7), (7, 4)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 11), (12, 12), (13, 13), (2, 2), (3, 3), (5, 4), (6, 5), (7, 7), (9, 10)], possible=[(11, 12), (4, 3), (6, 6)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (2, 1), (3, 2), (4, 3), (5, 4), (7, 4), (8, 5)], possible=[(6, 4)]),\n",
       "  LabeledAlignment(sure=[(10, 6), (11, 7), (14, 8), (17, 10), (18, 9), (2, 1), (21, 11), (22, 12), (23, 16), (25, 16), (26, 17), (29, 18), (3, 2), (31, 19), (33, 21), (34, 22), (35, 23), (36, 24), (37, 25), (38, 26), (43, 28), (44, 29), (46, 30), (47, 31), (48, 32), (5, 3), (6, 4), (8, 4), (9, 5)], possible=[(12, 8), (13, 8), (15, 9), (16, 9), (19, 12), (20, 12), (24, 16), (27, 17), (28, 18), (30, 19), (32, 20), (39, 27), (4, 7), (40, 27), (42, 27), (45, 29), (7, 4)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 8), (12, 9), (13, 10), (14, 12), (15, 13), (16, 15), (18, 18), (19, 19), (2, 2), (28, 22), (28, 23), (29, 25), (3, 3), (30, 26), (32, 27), (33, 28), (36, 24), (4, 4), (41, 31), (42, 32), (43, 33), (44, 33), (45, 33), (46, 35), (48, 34), (49, 36), (5, 5), (7, 6), (8, 7)], possible=[(11, 11), (13, 11), (15, 14), (23, 21), (24, 21), (25, 21), (26, 25), (27, 25), (31, 27), (31, 28), (34, 24), (35, 24), (37, 24), (40, 29), (41, 30), (47, 34), (6, 6), (6, 7), (9, 8)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 9), (11, 10), (13, 7), (18, 11), (19, 12), (20, 13), (21, 14), (22, 15), (23, 16), (25, 17), (26, 18), (3, 2), (4, 3), (5, 4), (6, 5), (7, 5), (8, 6), (9, 8)], possible=[(12, 7), (2, 4), (24, 17)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (3, 2)], possible=[(2, 2)]),\n",
       "  LabeledAlignment(sure=[(1, 1), (10, 9), (11, 10), (14, 13), (15, 15), (3, 2), (5, 3), (6, 4), (7, 5), (8, 8)], possible=[(12, 13), (13, 13), (14, 12), (2, 2), (4, 5), (9, 10)]),\n",
       "  LabeledAlignment(sure=[(10, 7), (12, 6), (13, 8), (14, 9), (16, 10), (17, 11), (19, 13), (2, 1), (21, 12), (23, 15), (27, 17), (28, 18), (29, 19), (3, 2), (6, 3), (7, 4), (8, 5)], possible=[(11, 6), (15, 10), (18, 13), (20, 12), (24, 16), (25, 16), (26, 17), (9, 7)])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from preprocessing import extract_sentences\n",
    "\n",
    "location =  'C:\\Work_life\\HSE_and_study\\ML and DS\\FCS ML 2\\HA\\EM\\data\\merged_data\\celex\\celex_21990A0714.wa'\n",
    "\n",
    "all_sentences = []\n",
    "all_targets = []\n",
    "# (´◕▽◕)⊃━☆\n",
    "# It is just a test of \n",
    "extract_sentences(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THAT TO THE GLOBAL PATH OF YOUR UNPACKED DATA\n",
    "dir_path = 'C:\\Work_life\\HSE_and_study\\ML and DS\\FCS ML 2\\HA\\EM\\data\\merged_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_21990A0714.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_22000A0411.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31958L0003.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31962L2645.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31965L0079.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31970L0220.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31975L0033.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31980L0799.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31985L0203.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\celex_31995L0070.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne01.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne02.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne03.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne04.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne05.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne06.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne07.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne08.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne09.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ne10.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2201.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2202.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2203.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2211.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2212.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2214.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2222.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2246.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2248.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2249.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2303.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2308.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2309.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2313.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2315.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2332.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2338.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2393.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2399.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2406.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2435.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\wsj_2436.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_bacchetta1.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_balcerowicz1.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_balibar1.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_balkenende1.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ban1.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_bck2.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_ber17.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_bertram19.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_blanchard8.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\project_syndicate_blo3.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\books_three_men_in_boat.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\kacenka_oliver_twist.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\kacenka_tess_durbervilles.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_00293.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_00393.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_00693.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_00793.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_00893.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_01193.wa',\n",
       " 'C:\\\\Work_life\\\\HSE_and_study\\\\ML and DS\\\\FCS ML 2\\\\HA\\\\EM\\\\data\\\\merged_data\\\\pcedt_rd_01493.wa']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdir_arr = listdir(dir_path)\n",
    "files = []\n",
    "for element in subdir_arr:\n",
    "    temp = map(lambda x: dir_path + '\\\\' + x ,listdir(dir_path + '\\\\' + element))\n",
    "    files.extend(temp)\n",
    "    \n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание -1. (0.5 балла)** Реализуйте функции `get_token_to_index` и `tokenize_sents` из модуля `preprocessing.py`, постройте словари token->index для обоих языков и постройте список из `TokenizedSentencePair` по выборке. Реализации функций также отправьте в Яндекс.Контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import get_token_to_index, tokenize_sents\n",
    "\n",
    "t_idx_src, t_idx_tgt = get_token_to_index(all_sentences)\n",
    "tokenized_sentences = tokenize_sents(all_sentences, t_idx_src, t_idx_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В качестве бейзлайна для этой задачи мы возьмём способ выравнивания слов по коэффициенту Дайса: слово в исходном языке является переводом слова на целевом языке, если они часто встречаются в одних и тех же предложениях и редко встречаются по отдельности. \n",
    "\n",
    "Математически это записывается по аналогии с мерой Жаккара: пусть $c(x,y)$ — число параллельных предложений, в которых есть и $x$ (на исходном языке), и $y$ (на целевом языке), а $c(x)$ и $c(y)$ — суммарное количество предложений, в которых встречается слово $x$ и $y$ соответственно. Тогда $\\textrm{Dice}(x,y)=\\frac{2 \\cdot c(x,y)}{c(x) + c(y)}$ — характеристика «похожести» слов $x$ и $y$. Она равна 1, если слова встречаются только в контексте друг друга (не бывает предложений только со словом $x$ без $y$ в переводе и наоборот), равна 0, если слова никогда не встречаются в параллельных предложениях и находится между пороговыми значениями в остальных случаях.\n",
    "\n",
    "В файле `models.py` описан абстрактный класс `BaseAligner`, наследником которого должны являться все модели в задании, а также приведён пример реализации `DiceAligner` выравнивания слов описанным выше путём. Ниже вы можете увидеть, как применять эту модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import DiceAligner\n",
    "\n",
    "baseline = DiceAligner(len(t_idx_src), len(t_idx_tgt), threshold=0.01)\n",
    "baseline.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Чтобы оценить качество модели выравнивания, пользуясь имеющейся разметкой, существует ряд автоматических метрик. Они подразумевают, что в разметке есть два вида выравниваний — «уверенные» (sure) и «возможные» (possible). Обозначим для конкретного предложения первое множество выравниваний $S$, второе — $P$, а предсказанные выравнивания — $A$; причём, в отличие от разметки в файле, $S\\subseteq P$. Тогда можно предложить три метрики, используя только операции над этими множествами:\n",
    "\n",
    "Precision $=\\frac{|A\\cap P|}{|A|}$. Отражает, какая доля предсказанных нами выравниваний вообще корректна; если мы дадим в качестве ответа все возможные пары слов в предложении, эта метрика сильно просядет.\n",
    "\n",
    "Recall $=\\frac{|A\\cap S|}{|S|}$. Эта метрика показывает, какую долю «уверенных» выравниваний мы обнаружили. Если мы попытаемся сделать слишком консервативную модель, которая выдаёт 0 или 1 предсказание на нетривиальных предложениях, полнота получится крайне низкая. \n",
    "\n",
    "Alignment Error Rate (AER) $=1-\\frac{|A\\cap P|+|A\\cap S|}{|A|+|S|}$. Метрика является комбинацией двух предыдущих и отслеживает общее качество работы системы, штрафуя оба описанных выше вида нежелаемого поведения модели. \n",
    "\n",
    "**Задание 0. (0.5 балла)** Реализуйте функции compute_precision, compute_recall, compute_aer из модуля metrics.py. Оцените качество бейзлайнового метода. Обратите внимание, что нужно использовать микро-усреднение во всех функциях: необходимо просуммировать числитель и знаменатель по всем предложениям и только потом делить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import compute_aer\n",
    "\n",
    "compute_aer(all_targets,baseline.align(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь мы можем перейти к базовой вероятностной модели для выравнивания слов. Пусть $S=(s_1,\\ldots,s_n)$ исходное предложение, $T=(t_1,\\ldots,t_m)$ — его перевод. В роли латентных переменных будут выступать выравнивания $A=(a_1,\\ldots,a_m)$ каждого слова в целевом предложении, причём $a_i\\in\\{1,\\ldots,n\\}$ (считаем, что каждое слово в $t$ является переводом какого-то слова из $s$). Параметрами модели является матрица условных вероятностей перевода: каждый её элемент $\\theta(y|x)=p(y|x)$ отражает вероятность того, что переводом слова $x$ с исходного языка на целевой является слово $y$ (нормировка, соответственно, совершается по словарю целевого языка). Правдоподобие латентных переменных и предложения на целевом языке в этой модели записывается так:\n",
    "\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i)p(t_i|a_i,S)=\\prod_{i=1}^m \\frac{1}{n}\\theta(t_i|s_{a_i}).\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 1. (2 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия ($\\mathcal{L}$ в обозначениях лекции и семинара). **Обратите внимание, что на M-шаге нужно найти аналитический максимум по параметрам.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (∩｀-´)⊃━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг E**:\n",
    "\n",
    "Матричная форма для этого шага представляет собой вычисление матрицы `C`, где каждый элемент `c_ij` равен ожидаемому количеству раз, когда исходное слово `f_i` связано с целевым словом `e_j`.\n",
    "\n",
    "$$\n",
    "C = \\frac{T(e | f)}{T(e | f) \\cdot \\mathbb{1}^T}\n",
    "$$\n",
    "\n",
    "где $\\mathbb{1}^T$ - это вектор-строка, состоящий из единиц, а $\\frac{T(e | f)}{T(e | f) \\cdot \\mathbb{1}^T}$ означает поэлементное деление.\n",
    "\n",
    "**Шаг M**:\n",
    "\n",
    "На этом шаге мы обновляем каждый элемент `T(e | f)` матрицы перевода `T` как `T_{new}(e | f)`. \n",
    "\n",
    "$$\n",
    "T_{new}(e | f) = \\frac{C}{\\mathbb{1} \\cdot C^T}\n",
    "$$\n",
    "\n",
    "где $\\mathbb{1}$ - это вектор-столбец, состоящий из единиц, а $\\frac{C}{\\mathbb{1} \\cdot C^T}$ означает поэлементное деление.\n",
    "\n",
    "**Нижняя оценка L**:\n",
    "\n",
    "Матричная форма нижней оценки L может быть выведена следующим образом:\n",
    "\n",
    "1. Для каждой пары предложений в параллельном корпусе вычислить матрицу `C`, где каждый элемент `c_ij` равен ожидаемому количеству раз, когда исходное слово `f_i` связано с целевым словом `e_j`. Это может быть вычислено как $C = \\frac{T(e | f)}{T(e | f) \\cdot \\mathbb{1}^T}$ для всех `i` в `[0, l_f]`.\n",
    "2. Затем вычислить новые вероятности перевода, обновляя каждый элемент `T(e | f)` матрицы перевода `T` как $T_{new}(e | f) = \\frac{C}{\\mathbb{1} \\cdot C^T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (∩｀-´)⊃━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 2. (2.5 балла)** Реализуйте все методы класса `WordAligner` в соответствии с полученными вами формулами. Протестируйте вашу реализацию через Яндекс.Контест, а здесь обучите модель и посчитайте её AER на истинной разметке. Чтобы предсказать выравнивание для пары предложений в этой модели, следует выбирать в соответствие для слова в целевом предложении с индексом $i$ позицию, соответствующую максимуму апостериорного распределения $p(a_i|T,S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import WordAligner\n",
    "\n",
    "word_aligner = WordAligner(len(t_idx_src), len(t_idx_tgt), 20)\n",
    "word_aligner.fit(tokenized_sentences);\n",
    "\n",
    "# ༼つ ಠ益ಠ༽つ ─=≡ΣO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заметим, что таблицу вероятностей перевода можно использовать и саму по себе для построения словарей. Пример работы показан ниже: метод хоть и работает, но мягко говоря, неидально — слишком мало данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx_token_tgt = {index:token for token, index in t_idx_tgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mr']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mrs']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['water']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['depended']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['on']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 3. (0.5 балла)** Мы смогли получить матрицу условных вероятностей перевода исходного языка в целевой. Можно ли, пользуясь этой матрицей и ещё какими-то статистиками по параллельному корпусу, получить вероятности перевода целевого языка в исходный? Реализуйте такой метод и приведите ниже пример его работы, показав пару удачных переводов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (>ω<)ノ—==ΞΞ☆*✲ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 4. (0.5 балла)** Визуализируйте полученные выравнивания для нескольких предложений в виде heatmap: по одной из осей располагаются токены исходного текста, по другой — токены его перевода, на пересечении позиций $i$ и $j$ — 0 либо 1 в зависимости от того, является ли в обученной модели $a_i$ равным $j$. Можете ли вы их проинтерпретировать? Постройте аналогичный график, но без дискретизации, а визуализируя напрямую апостериорное распределение. Можете ли вы найти ситуации, в которых модель не уверена, переводом какого слова является слово $i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (•̀ 3 •́)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заметим, что при задании модели мы сделали довольно сильное предположение о том, что вероятности выбора слова для выравнивания никак не зависят от позиции слова в целевом предложении. Можно сделать эти вероятности настраиваемыми параметрами, получив прямоугольную матрицу $\\phi_{m,n}(j|i)=p(a_i=j|m,n)$ для каждой пары длин предложений $m,n$: по-прежнему мы получаем распределение над индексами в исходном предложении. Тогда модель приобретает вид\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i|m,n)p(t_i| a_i, S)=\\prod_{i=1}^m \\phi_{m,n}(a_i|i)\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 5. (1.5 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ଘ(๑˃̵ᴗ˂̵)━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 6. (2 балла)** Реализуйте все методы класса `WordPositionAligner`, протестируйте их корректность через Яндекс.Контест. Обучите модель, оцените её качество на истинной разметке и сравните его с качеством предыдущей более простой модели. Проиллюстрируйте влияние стартовых параметров на результат, проинициализировав эту модель параметрами модели из задания 2 (важно, чтобы суммарное число эпох обучения в обоих сценариях оставалось тем же)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import WordPositionAligner\n",
    "# (≧ ◡ ≦)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 7. (1 балл)** В предыдущих пунктах мы никак не заостряли внимание на предобработке текстов, что может негативно влиять на результаты обученной модели. Например, сейчас метод выравнивания учитывает регистр, а слова на чешском языке вдобавок обладают богатой морфологией и большим количеством диакритических знаков. Если сократить количество параметров модели (различных слов), можно ускорить обучение и добиться лучших результатов, потому что статистики по словам будут считаться по большему числу параллельных предложений.\n",
    "\n",
    "Примените к исходным данным [Unicode-нормализацию](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization), приведите их к нижнему регистру и обучите модель выравнивания заново. Сравните качество и скорость обучения с предыдущими результатами и сделайте выводы. Если вы найдете в данных ещё какие-то проблемы, которые можно исправить более грамотной предобработкой, также продемонстрируйте, как их решение влияет на качество.\n",
    "\n",
    "**Важно:** здесь и далее в процессе обработки данных у вас может получаться, что из тестовых данных будут удалены предложения из-за отсутствия слов в словаре. Если такое всё же произошло, для корректности сравнения считайте AER вашей модели на удалённых предложениях равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (੭•̀ω•́)੭̸*✩⁺˚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 7. (бонус, до 3 баллов)** \n",
    "\n",
    "Улучшите качество получившейся системы настолько, насколько сможете. За каждые 5 процентов, на которые AER на тех же данных получается меньше, чем минимум ошибки всех предыдущих моделей, вы получите по 1 бонусному баллу.\n",
    "\n",
    "Ниже приведены несколько идей, которые могут помочь вам повысить \n",
    "\n",
    "* Модифицировать модель: как вы можете понять, недостатком второго реализованного вами подхода является избыточное число параметров из-за необходимости подерживать отдельную матрицу для каждой различной пары длин предложений в корпусе. В статье https://www.aclweb.org/anthology/N13-1073.pdf приведён способ снижения числа параметров, задающих априорное распределение позиций выравнивания, который позволяет в десять раз быстрее обучать модель и получать лучшее качество.\n",
    "* Агрегация по двум направлениям: в статье https://www.aclweb.org/anthology/J03-1002/ утверждается, что асимметричность выравниваний вредит качеству, потому что из-за выбранной модели одному слову в целевом предложении не может соответствовать два слова в исходном предложении. Для решения этой проблемы (и улучшения метрик, разумеется) авторы предлагают несколько алгоритмов, которые можно попробовать применить в этом задании.\n",
    "* Использовать больше обучающих данных. В корпусе, которым мы пользуемся, только пара тысяч предложений, чего может не хватать для по-настоящему хорошей модели выравнивания. Разумеется, неразмеченных параллельных английско-чешских корпусов гораздо больше, поэтому можно воспользоваться ими. Хорошая точка для старта — данные с соревнования по машинному переводу  [воркшопа WMT](http://www.statmt.org/wmt20/translation-task.html).\n",
    "* В языках часто существуют слова наподобие артиклей или предлогов, которым не соответствует ни одно слово в переводе. Все рассмотренные в рамках задания модели это не учитывают, возможно, добавление возможности перевода в «нулевой» токен улучшит качество модели (при тестировании такие выравнивания имеет смысл выбрасывать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ┐_(ツ)_┌━☆ﾟ.*･｡ﾟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
